[
  {
    "objectID": "project/index.html",
    "href": "project/index.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nüßº TBD\n\n\nTBD\n\n\n\nMay 16, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n      Yue\n      Harriet Huang\n    ",
    "section": "",
    "text": "I‚Äôm a data technologist.\n    \n    About Me ‚Üí\n  \n\n  \n    \n      Go to Home"
  },
  {
    "objectID": "index.html#latest-posts",
    "href": "index.html#latest-posts",
    "title": "\n      Yue\n      Harriet Huang\n    ",
    "section": "Latest Posts",
    "text": "Latest Posts\n\n\n\n\n\n\n\n\n\n\nHow to enable your Quarto blogs to accept comments with Giscus\n\n\nTBD\n\n\n\nMay 16, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#latest-projects",
    "href": "index.html#latest-projects",
    "title": "\n      Yue\n      Harriet Huang\n    ",
    "section": "Latest Projects",
    "text": "Latest Projects\n\n\n\n\n\n\n\n\n\n\nüßº TBD\n\n\nTBD\n\n\n\nMay 16, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#latest-talks",
    "href": "index.html#latest-talks",
    "title": "\n      Yue\n      Harriet Huang\n    ",
    "section": "Latest Talks",
    "text": "Latest Talks\n\n\n\n\n\n\n\n\n\n\nAchieving Concurrency in Streamlit with a RQ scheduler, Building Responsive Data Applications\n\n\nTBD\n\n\n\nJun 1, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#latest-podcasts",
    "href": "index.html#latest-podcasts",
    "title": "\n      Yue\n      Harriet Huang\n    ",
    "section": "Latest Podcasts",
    "text": "Latest Podcasts\n\n\n\n\n\n\n\n\n\n\nAchieving Concurrency in Streamlit with a RQ scheduler, Building Responsive Data Applications\n\n\nTBD\n\n\n\nJun 1, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talk/isg-2018/index.html",
    "href": "talk/isg-2018/index.html",
    "title": "Unsupervised behavior change detection using passive sensor systems in the homes of older adults",
    "section": "",
    "text": "Abstract\n\nPurpose\nGlobally and within the United States, we face well-known and documented challenges driven by growth within the elderly segments of our population. The majority of adults over 65 are healthy but managing one or more chronic illnesses, and older adults and their informal caregivers‚Äîsuch as family members and friends‚Äîrequire supportive technologies that assist in monitoring and managing these conditions1 as they strive to maintain independence at home. An important goal of lifestyle reassurance monitoring is to alert older adults and their caregivers to changes in behavior or routine. In contrast with traditional activity recognition algorithms that require labelled activity data that is both difficult and expensive to collect2, we present a method for unsupervised behavior change detection that does not require explicit, higher-level activity labels and is effective when applied to real-world, natural, smart home activity data.\n\n\nMethods\nIn this project, we developed a passive sensor system that has been installed to date in the homes of 14 community-dwelling, older adults (aged 68 and above) who live alone and were of good health at the time of installation. Participants responded to a bi-weekly survey tracking the occurrence of health changes. Included in the sensor network are motion sensors for the generalized detection of presence throughout the home, and magnetic contact sensors for detection of interaction with entrance and exit doors and routinely used objects. All sensors are wireless, use the Z-Wave protocol, and are readily available commercially. The basis of the behavior change algorithm is the use of a bag of event sequence n-grams representation3 to summarize daily activity patterns in an activity profile and a permutation-based change detection algorithm4 to compare activity profiles of multiple days (e.g.¬†a baseline period of activity) and individual or grouped activity profiles.\n\n\nResults and Discussion\nThe bag of event n-grams method was first validated as a supervised classification problem in which activity profiles were used to identify occupants from 6 homes with identical layouts. Activity profiles based on 4 and 6 weeks of activity led to correct identification of a given occupant for unlabelled days of activity with high accuracy (0.9593, 0.9624) and F1 (0.9590, 0.9621). The algorithm for unsupervised behavior change was applied to the activity data from four participants over a period of one year (one participant) or two years (three participants) who reported health changes ranging from acute episodes of illness to mobility restrictions leading to major surgery. Preliminary results reveal that comparison of activity profiles over time windows of 1 to 4 weeks reliably detects major shifts in behavior or other systematic disturbances such as guests in the home or sensor reliability issues. Linking the output of the algorithm to a notification system will alert family members, caregivers, and system administrators to trigger follow-up and review when such issues arise.\n\n\nReferences\n\nDemiris G, Hensel BK. Technologies for an aging society: A systematic review of ‚Äúsmart home‚Äù applications. Yearbook of medical informatics. 2008 Jan;33‚Äì40\nSzewcyzk S, Dwan K, Minor B, Swedlove B, Cook D. Annotating smart environment sensor data for activity learning. Technology and Health Care. 2009 Jan;17(3):161‚Äì169.\nHamid R, Johnson A, Batta S, Bobick A, Isbell C, Coleman G. Detection and explanation of anomalous activities: Representing activities as bags of event n-grams. Proceedings - 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2005. 2005;1031‚Äì1038.\nSprint G, Cook DJ, Schmitter-Edgecombe M. Unsupervised detection and analysis of changes in everyday physical activity data. Journal of Biomedical Informatics. 2016 Oct;63(Supplement C):54‚Äì65"
  },
  {
    "objectID": "talk/informs-2013/index.html",
    "href": "talk/informs-2013/index.html",
    "title": "Boosted Tree Ensembles for Predicting Postsurgical ICU Mortality",
    "section": "",
    "text": "Real-time monitoring of patient conditions in the ICU environment is essential in supporting clinical decisions and ensuring optimal allocation of medical resources. This study focuses on accurately predicting in-hospital ICU patient mortality utilizing functional profile data. We demonstrate that a boosted trees ensemble model is well suited for the diverse data typologies present in ICU data and provides an interpretable and accurate model to aid clinical experts in critical ICU decisions."
  },
  {
    "objectID": "talk/drake-intro-biodataclub/index.html",
    "href": "talk/drake-intro-biodataclub/index.html",
    "title": "Reproducible Data Workflows With Drake",
    "section": "",
    "text": "drake is an R package that provides a powerful, flexible workflow management tool for reproducible data analysis pipelines. drake alleviates the pain of managing large (and even small) data analyses, speeding up iteration and development while providing reproducibility guarantees that are essential for modern research.\nhttps://ropensci.github.io/drake/\nIn this session, we‚Äôll learn how to use drake to manage a data analysis workflow by writing functions that define the steps of the analysis. We‚Äôll then learn how drake can keep track of all of these steps, from start to finish, and intelligently update only the outdated steps when your data or code change.\n\nMeeting prerequisites\nWe‚Äôll work through a few examples together, so please bring a laptop with the drake and visNetwork packages installed. (If you don‚Äôt have a laptop you can share with someone who does at the session.) You would also benefit from installing the tidyverse package for the session. See the full requirements here.\nrequired_packages &lt;- c(\n  # \"tidyverse\",  #&lt;&lt; For data processing, etc. (you probably have this)\n  \"here\",         #&lt;&lt; For sane path management\n  \"cowplot\",      #&lt;&lt; For composing ggplot2 plots\n  \"visNetwork\",   #&lt;&lt; For visualizing drake plans\n  \"drake\"         #&lt;&lt; Because drake\n)\n\ninstall.packages(required_packages)\nNote: if you‚Äôve used drake before, please ensure that you have version 7.0.0 or later installed.\n\n\nMeeting materials\nThe slides from this talk are available online at https://pkg.garrickadenbuie.com/drake-intro/ and the drake source code and RStudio project are in available on GitHub at https://github.com/gadenbuie/drake-intro. There is also an RStudio Cloud project containing the drake project with all of the required dependencies pre-installed that you can use to explore and run the code from the talk."
  },
  {
    "objectID": "podcast/trug-extra-awesome-xaringan/index.html",
    "href": "podcast/trug-extra-awesome-xaringan/index.html",
    "title": "Extra Awesome xaringan Presentations",
    "section": "",
    "text": "Learn how to make extra awesome xaringan presentations with a few new packages\n\nxaringanthemer\nxaringanExtra\nmetathis\n\nthat add the extra touches needed to personalize your slides and make them stand out from the crowd."
  },
  {
    "objectID": "podcast/trug-extra-awesome-xaringan/index.html#description",
    "href": "podcast/trug-extra-awesome-xaringan/index.html#description",
    "title": "Extra Awesome xaringan Presentations",
    "section": "",
    "text": "Learn how to make extra awesome xaringan presentations with a few new packages\n\nxaringanthemer\nxaringanExtra\nmetathis\n\nthat add the extra touches needed to personalize your slides and make them stand out from the crowd."
  },
  {
    "objectID": "podcast/presentable-user2021/index.html",
    "href": "podcast/presentable-user2021/index.html",
    "title": "Professional, Polished, Presentable",
    "section": "",
    "text": "The xaringan package brings professional, impressive, and visually appealing slides to the powerful R Markdown ecosystem. Through our hands-on tutorial, you will learn how to design highly effective slides that support presentations for teaching and reporting alike. Over three hours, you will learn how to create an accessible baseline design that matches your institution or organization‚Äôs style guide. Together we‚Äôll explore the basics of CSS‚Äîthe design language of the internet‚Äîand how we can leverage CSS to produce elegant slides for effective communication."
  },
  {
    "objectID": "podcast/presentable-user2021/index.html#abstract",
    "href": "podcast/presentable-user2021/index.html#abstract",
    "title": "Professional, Polished, Presentable",
    "section": "",
    "text": "The xaringan package brings professional, impressive, and visually appealing slides to the powerful R Markdown ecosystem. Through our hands-on tutorial, you will learn how to design highly effective slides that support presentations for teaching and reporting alike. Over three hours, you will learn how to create an accessible baseline design that matches your institution or organization‚Äôs style guide. Together we‚Äôll explore the basics of CSS‚Äîthe design language of the internet‚Äîand how we can leverage CSS to produce elegant slides for effective communication."
  },
  {
    "objectID": "podcast/presentable-user2021/index.html#why-xaringan",
    "href": "podcast/presentable-user2021/index.html#why-xaringan",
    "title": "Professional, Polished, Presentable",
    "section": "Why xaringan?",
    "text": "Why xaringan?\nEffective communication is the keystone of impactful data science. Whether teaching data-related skills or reporting the latest modelling results, by and large R users are expected to communicate highly complex topics to students and stakeholders. Furthermore, our computational data work requires that our presentations and reports are both reproducible when we need to recreate today‚Äôs work in the future, as well as adaptable when tomorrow‚Äôs data changes today‚Äôs results. And, not least of all, effective communication demands that our medium of communication is accessible to all, regardless of socio-economic status, activity limitations or disability.\nCreating presentations with the xaringan package embodies all of these requisite skills: built on the literate programming markdown syntax familiar to users of R Markdown, it produces reproducible HTML slides that enable effective, accessible communication across sectors, disciplines, and experiences.\nAlong the way, working with xaringan fosters a level of web literacy that is immensely useful in many other venues of online communication such as with web-based documents and apps created using R Markdown and Shiny."
  },
  {
    "objectID": "podcast/js4shiny/index.html",
    "href": "podcast/js4shiny/index.html",
    "title": "JavaScript for Shiny Users",
    "section": "",
    "text": "Shiny gives users a powerful toolkit to create interactive web applications. As a result, Shiny users are also web developers! Inevitably, an intermediate Shiny user will want to create a visualization or user interface that isn‚Äôt available in the shiny package. Fortunately, we can use the building blocks of the web ‚Äì JavaScript, HTML, and CSS ‚Äì to extend Shiny‚Äôs capabilities and create engaging Shiny apps.\nThis two-day, hands-on workshop will introduce Shiny users to JavaScript, the ubiquitous scripting language that powers the modern web. We will explore JavaScript‚Äôs syntax and will discover its functional programming style to be refreshingly familiar to tidyverse R users. We will learn how to use JavaScript to manipulate HTML and how Shiny uses JavaScript to communicate between the browser and Shiny server. Together, we will build an htmlwidget and learn how to incorporate our own or packaged JavaScript code into Shiny apps and [R Markdown] documents, and how to simultaneously manage JavaScript and R dependencies.\nThis workshop is for the Shiny user who boldly waded into the Customizing Shiny section of RStudio‚Äôs Shiny Articles and quickly wished they had more experience with JavaScript. This user recognizes the benefits of learning JavaScript, but they are overwhelmed by the sheer number of packages, tutorials, and StackOverflow questions that exist in the world about JavaScript, HTML, and CSS. The goal of this workshop is to meet the Shiny user where they are now to learn the best parts of JavaScript that will provide the most value and facilitate learning and exploration after the workshop."
  },
  {
    "objectID": "podcast/js4shiny/index.html#abstract",
    "href": "podcast/js4shiny/index.html#abstract",
    "title": "JavaScript for Shiny Users",
    "section": "",
    "text": "Shiny gives users a powerful toolkit to create interactive web applications. As a result, Shiny users are also web developers! Inevitably, an intermediate Shiny user will want to create a visualization or user interface that isn‚Äôt available in the shiny package. Fortunately, we can use the building blocks of the web ‚Äì JavaScript, HTML, and CSS ‚Äì to extend Shiny‚Äôs capabilities and create engaging Shiny apps.\nThis two-day, hands-on workshop will introduce Shiny users to JavaScript, the ubiquitous scripting language that powers the modern web. We will explore JavaScript‚Äôs syntax and will discover its functional programming style to be refreshingly familiar to tidyverse R users. We will learn how to use JavaScript to manipulate HTML and how Shiny uses JavaScript to communicate between the browser and Shiny server. Together, we will build an htmlwidget and learn how to incorporate our own or packaged JavaScript code into Shiny apps and [R Markdown] documents, and how to simultaneously manage JavaScript and R dependencies.\nThis workshop is for the Shiny user who boldly waded into the Customizing Shiny section of RStudio‚Äôs Shiny Articles and quickly wished they had more experience with JavaScript. This user recognizes the benefits of learning JavaScript, but they are overwhelmed by the sheer number of packages, tutorials, and StackOverflow questions that exist in the world about JavaScript, HTML, and CSS. The goal of this workshop is to meet the Shiny user where they are now to learn the best parts of JavaScript that will provide the most value and facilitate learning and exploration after the workshop."
  },
  {
    "objectID": "podcast/informs-2017/index.html",
    "href": "podcast/informs-2017/index.html",
    "title": "Occupant Activity Profiles from Smart Home Sensor Event Streams",
    "section": "",
    "text": "Faced with a growing elderly population, learning and characterizing activity profiles of smart home occupants will support senior health care management for older adults living in homes augmented by ambient intelligence solutions that combine ubiquitous computing and artificial intelligence. In this work, we explore a bag of n-grams approach for creating occupant-specific activity profiles from event streams collected from passive, embedded sensors in real-world sensor networks in the homes of several older adults."
  },
  {
    "objectID": "podcast/iie-iserc-2015/index.html",
    "href": "podcast/iie-iserc-2015/index.html",
    "title": "Ambient Intelligence Applications in Healthcare",
    "section": "",
    "text": "In the past century, the world has experienced unprecedented growth in life expectancy concurrent with a growth in elderly population. Between 2010 and 2050, the number of people aged 65 and older is expected to more than double to exceed 88 million by 2050 in the United States. Ambient intelligence merges ubiquitous computing, embedded sensors, and artificial intelligence to monitor, adjust and respond to the environment of the user. This presentation will explore the potential of ambient intelligence for applications in health care, primarily with a focus on senior health care management."
  },
  {
    "objectID": "podcast/gentle-ggplot2-usf-asu/index.html",
    "href": "podcast/gentle-ggplot2-usf-asu/index.html",
    "title": "A Gentle Guide to the Grammar of Graphics with ggplot2",
    "section": "",
    "text": "An intruction to data visualization with ggplot2 presented at the ‚ÄúWorkshop on Data Analysis Using R‚Äù hosted by the ASA student chapter at USF."
  },
  {
    "objectID": "colophon/index.html",
    "href": "colophon/index.html",
    "title": "Made with üíô",
    "section": "",
    "text": "Made with  Quarto, which is powered by pandoc.\nThe previous version of this blog was made with  Hugo Ap√©ro , which is based on  Blogophonic  by Formspree and was powered by blogdown and built by Hugo.\nThe source for this blog can be found online at GitHub gadenbuie/garrickadenbuie-com."
  },
  {
    "objectID": "colophon/index.html#made-with-quarto",
    "href": "colophon/index.html#made-with-quarto",
    "title": "Made with üíô",
    "section": "",
    "text": "Made with  Quarto, which is powered by pandoc.\nThe previous version of this blog was made with  Hugo Ap√©ro , which is based on  Blogophonic  by Formspree and was powered by blogdown and built by Hugo.\nThe source for this blog can be found online at GitHub gadenbuie/garrickadenbuie-com."
  },
  {
    "objectID": "colophon/index.html#usesgarrick",
    "href": "colophon/index.html#usesgarrick",
    "title": "Made with üíô",
    "section": "/uses/garrick",
    "text": "/uses/garrick\nI don‚Äôt have a /uses page (yet!), but I did live tweet and blog about my MacBook Pro setup. That should get you pretty close to a full accounting of the software and tools I use on a daily basis."
  },
  {
    "objectID": "colophon/index.html#license",
    "href": "colophon/index.html#license",
    "title": "Made with üíô",
    "section": "License",
    "text": "License\nMy blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n\n\n\nUnless otherwise specified, code presented in blog posts are released under the MIT license."
  },
  {
    "objectID": "blog/visualize-physionet-data-with-r/index.html",
    "href": "blog/visualize-physionet-data-with-r/index.html",
    "title": "Visualizing PhysioNet Challenge Patient Data with R",
    "section": "",
    "text": "In working with the PhysioNet Challenge 2012 data set, it can often be very difficult to assess the condition of a given patient, or the trends within those the time series variables provided.\nThere is a lot of variability between the number of variables recorded (and the number of observations per variable) for each patient. As a medical data set, the data is characterized by highly non-linear trends, and it can be difficult to get a handle on it in a table format. Worse, the training set is nearly 2 million rows long when training patient data is joined together ‚Äî a result of presenting patient data in three rows: Time, Parameter, Value.\nFurthermore, there is a large variation in the reliability of the data recorded in each variable. A machine-read variable may be more reliable than a variable whose observations are recorded by hand by a human.\nThus, in exploring the data set, it may be useful at times to visually see the input data validate model output or to explore unusual cases or values. R provides a straight-forward language with good packages for pretty graphs, making it a good choice for this type of visualization.\n\nA nice looking plot\nThis post will help you learn to run R code that produce graphs like this. (Note: learn to run, not learn to write‚Ä¶ that‚Äôs a much longer post and maybe I‚Äôll get to it later.)\n\nThe image shows all of the time-series variables available for patients in Set A, ordered alphabetically, with a fixed time scale in minutes after arrival in the ICU. Descriptive variables, including some calculated variables, are printed at the top of the plot.\nThe plot is generated by sending a list of RecordID‚Äôs to a function, plotByID(), which will either display the plot on the screen, or save it to the working directory.\n\n\nGetting Started\nFirst, download and install RStudio. This should be relatively painless. You‚Äôll also need the code and the data set. The original data set is from the PhysioNet 2012 Computing in Cardiology. I‚Äôve simply pulled each individual patient file into one dataset and added a new column for RecordID.\nExtract plotByID.zip somewhere where you‚Äôll find it and fire up RStudio. You should see a screen that looks a lot like this:\n\nYou‚Äôve got the Console on the left, Workspace and Files on the right. This code uses Hadley Wickham‚Äôs excellent plotting package ggplot2, which isn‚Äôt installed by default. To install it, click on Install packages¬†under the¬†Tools menu, type ggplot2 in the text box and hit enter. Everything should install fine.\nTo load the code, click on the ‚Ä¶¬†in the Files pane and open the folder where you extracted the data set. To make sure everything runs within this directory, click¬†‚ÄúSet working directory‚Äù under the More¬†button. Open plotByID.R. Now you should see this:\n\nThe code to load and plot the data is now open in the upper left window. Take a look at it and read through it if you want. To load it up, simply select everything (Ctrl/‚åò+A) and then click Run¬†or hit Ctrl/‚åò+Enter. The data set and necessary functions will load, and the demo plot above will appear, like magic.\n\n\nUsing plotByID()\nThe plotting function is pretty self-explanatory. It takes a primary argument of a RecordID or a vector of RecordIDs and returns a plot. There are also arguments to save the plot to a particular path and to control whether or not the plot displays on the screen.\nTo plot input patient data to the screen you only have to enter one RecordID, by simply typing\nplotByID(133966)\nin the console and hitting enter. To plot multiple patients, use a vector, which in R is denoted by the command c(). Thus,\nplotByID( c(133966, 140334) )\nwill plot the input data for two patients. To plot a random sample of 10 patients use the sample() function:\nplotByID( sample(seta$RecordID, 10 )\nIf you want the images to save to the working directory, use\nplotByID(133966, save=TRUE, path=path)\nYou don‚Äôt have to manually specify the path variable, it‚Äôs been set to the working directory. If you want to change the saving path, set\npath=\"~/Your/Directory/Here\"\nThat‚Äôs it. I hope this makes it a little easier to see what you‚Äôre working with! ;)"
  },
  {
    "objectID": "blog/upcoming-code-and-data-boot-camp/index.html",
    "href": "blog/upcoming-code-and-data-boot-camp/index.html",
    "title": "Upcoming Code & Data Boot Camp",
    "section": "",
    "text": "Today, Dr.¬†Shabbir Ahmed spoke at USF at our lecture series on Stochastic Integer Programming methods. It was high-level and broad and unfortunately he didn‚Äôt get into many of the ‚Äúnitty-gritty‚Äù details, but it was still fascinating. Clearly integer programming ‚Äì and SIP more specifically ‚Äì is going to be an even more important area in OR and optimization in the very near future.\nAt the end of the talk, in answer to one of the questions, Dr.¬†Ahmed spoke a bit about his advice to current and future students of industrial engineering. He advised young students to learn programming skills and to embrace what is traditionally thought of as ‚Äúcomputer science‚Äù. They are important skills too often left out of IE curricula but that are highly valuable and relevant to the work of IEs in the field.\nIt was a heartening statement to hear, given that our INFORMS student chapter has organized a two-day intense introduction to programming ‚Äúboot camp‚Äù we‚Äôll be running next week called the‚Ä¶"
  },
  {
    "objectID": "blog/upcoming-code-and-data-boot-camp/index.html#power-up-code-data-boot-camp",
    "href": "blog/upcoming-code-and-data-boot-camp/index.html#power-up-code-data-boot-camp",
    "title": "Upcoming Code & Data Boot Camp",
    "section": "Power Up! Code & Data Boot Camp",
    "text": "Power Up! Code & Data Boot Camp\nI‚Äôm very happy to see this vision realized and to be a part of the boot camp. I love talking about code ‚Äì not something that I get to do everyday, at least not without a few hairy eyeballs.\nAs the first time hosting this, I think we have a great spread of topics and a great lineup of USF IMSE graduate students. Presentations will include\n\nMatlab\nR\nMinitab\nExcel\nand SAS\n\nwith at least one introductory session and one advanced ‚Äúhands-on‚Äù session for each. I already have some ideas about how we host this again next year, but for now I‚Äôve got to focus on getting my three sessions together.\nI‚Äôll be talking motivating students to use R, talking about the fundamentals of R for data anayltics, and using R, knitr and pandoc for reproducible research. I‚Äôm excited to get people talking about R, but I‚Äôm most excited about getting my fellow graduate students into using pandoc and knitr. Because they‚Äôre awesome."
  },
  {
    "objectID": "blog/trump-tweet-time/index.html",
    "href": "blog/trump-tweet-time/index.html",
    "title": "Trump Tweet Time: An 8-bit ‚ÄúExecutive Time‚Äù Game",
    "section": "",
    "text": "Last week, Donald Trump‚Äôs White House schedule was leaked and published online by Axios. One highlight from the released documents is the large amount of unstructured ‚ÄúExecutive Time‚Äù that appears on his schedule.\nThe #rstats Twitter community immediately began to wonder what interesting anaylses could be done in comparing Trump‚Äôs schedule to the tweets he sent out.\n\n\nHere‚Äôs something simple, using tweets from the #TrumpTwitterArchive so limited to midterms to end of 2018. pic.twitter.com/CdRxUNwyq2\n\n‚Äî Garrick Aden-Buie (@grrrck) February 4, 2019\n\nAxios helpfully released a Google Spreadsheet to accompany the PDF version of the schedule, and a curated version has also been posted on Data World. Jonathan Sidi also built a cool Shiny app for viewing Trumps tweets on a time line over his schedule.\nI started to pull together an analysis for an upcoming blog post, and here‚Äôs a little sneak peak.\n\n\nHere's something simple, using tweets from the #trumptwitterarchive so limited to midterms to end of 2018. pic.twitter.com/CdRxUNwyq2\n\n‚Äî Garrick Aden-Buie (@grrrck) February 4, 2019"
  },
  {
    "objectID": "blog/trump-tweet-time/index.html#trumps-excutive-time",
    "href": "blog/trump-tweet-time/index.html#trumps-excutive-time",
    "title": "Trump Tweet Time: An 8-bit ‚ÄúExecutive Time‚Äù Game",
    "section": "",
    "text": "Last week, Donald Trump‚Äôs White House schedule was leaked and published online by Axios. One highlight from the released documents is the large amount of unstructured ‚ÄúExecutive Time‚Äù that appears on his schedule.\nThe #rstats Twitter community immediately began to wonder what interesting anaylses could be done in comparing Trump‚Äôs schedule to the tweets he sent out.\n\n\nHere‚Äôs something simple, using tweets from the #TrumpTwitterArchive so limited to midterms to end of 2018. pic.twitter.com/CdRxUNwyq2\n\n‚Äî Garrick Aden-Buie (@grrrck) February 4, 2019\n\nAxios helpfully released a Google Spreadsheet to accompany the PDF version of the schedule, and a curated version has also been posted on Data World. Jonathan Sidi also built a cool Shiny app for viewing Trumps tweets on a time line over his schedule.\nI started to pull together an analysis for an upcoming blog post, and here‚Äôs a little sneak peak.\n\n\nHere's something simple, using tweets from the #trumptwitterarchive so limited to midterms to end of 2018. pic.twitter.com/CdRxUNwyq2\n\n‚Äî Garrick Aden-Buie (@grrrck) February 4, 2019"
  },
  {
    "objectID": "blog/trump-tweet-time/index.html#an-8-bit-distraction",
    "href": "blog/trump-tweet-time/index.html#an-8-bit-distraction",
    "title": "Trump Tweet Time: An 8-bit ‚ÄúExecutive Time‚Äù Game",
    "section": "An 8-bit Distraction",
    "text": "An 8-bit Distraction\nBut then I got distracted. Colin Fay recently released a port of ness-css for Shiny called nessy, and it looks awesome. I just needed a good reason to create an awesome 8-bit retro Shiny app.\nThe idea came to me during the analysis. Can you tell what Trump is doing (or is supposed to be doing) by the tweets he sends? Why not put your intuition to the test?"
  },
  {
    "objectID": "blog/trump-tweet-time/index.html#trump-tweet-time",
    "href": "blog/trump-tweet-time/index.html#trump-tweet-time",
    "title": "Trump Tweet Time: An 8-bit ‚ÄúExecutive Time‚Äù Game",
    "section": "Trump Tweet Time",
    "text": "Trump Tweet Time\nSo I built a simple Shiny game called Trump Tweet Time that you can play right now. An 8-bit Trump shouts a tweet at you and you have to guess what was on his schedule while he was tweeting.\n\n\n\n\n\nA screenshot of a SuperNES-styled Donald Trump with a speach bubble containing a random tweet. Three buttons offer the options for ‚Äúmeeting‚Äù, ‚Äútravel‚Äù or ‚Äúexecutive time‚Äù\n\n\n\n\n\n\n\nA screenshot after the user has clicked ‚Äúexecutive time‚Äù revealing that Trump tweeted during Executive Time.\n\n\n\n\nThanks to Colin Fay for nessy and Mike Kearney for rtweet! Your packages made this fun and easy.\nNow go enjoy some executive time!"
  },
  {
    "objectID": "blog/the-end-of-stanford/index.html",
    "href": "blog/the-end-of-stanford/index.html",
    "title": "The End of Stanford?",
    "section": "",
    "text": "‚Ä¶the center of gravity at the university appears to have shifted. The school now looks like a giant tech incubator with a football team.\n\n[NY Times]"
  },
  {
    "objectID": "blog/the-end-of-stanford/index.html#the-end-of-stanford",
    "href": "blog/the-end-of-stanford/index.html#the-end-of-stanford",
    "title": "The End of Stanford?",
    "section": "",
    "text": "‚Ä¶the center of gravity at the university appears to have shifted. The school now looks like a giant tech incubator with a football team.\n\n[NY Times]"
  },
  {
    "objectID": "blog/respond-peer-reviews-with-pandoc/index.html",
    "href": "blog/respond-peer-reviews-with-pandoc/index.html",
    "title": "Responding to peer reviewers with Pandoc",
    "section": "",
    "text": "I‚Äôm in the process of responding to the second round of peer reviews of a paper I‚Äôve spent considerable time working on over the past year. Of course, this time around I‚Äôve learned a few new tricks that make the whole process easier to manage‚Ä¶\n\nI spent an entire weekend converting the paper from Word to LaTeX. By hand. But it‚Äôs now worth it.\nI coerced the other graduate student working on the paper to use Trello, so I can see what he‚Äôs working on now, what he‚Äôs planning to do next and what he‚Äôs already done.\nI‚Äôve learned to use git in combination with BitBucket so individual changes are tracked and it‚Äôs easy to flip between old and current versions of the paper with a simple git checkout.\nI‚Äôve learned how to use the powerful markdown language and document converter, pandoc, which I‚Äôm using to format our response to the reviewers.\n\nI‚Äôm following the format presented by Matt Might in Responding to peer review. It is an excellent guide to writing a response to peer reviewers, and the method he outlines fits perfectly into a pandoc workflow.\nFor example, the journal to which we are submitting is run by Elsevier, who certainly has a platform to coordinate communication between editors, authors, and reviewers. A platform that conveniently strips all formatting from the review text. But, after simply copying and pasting the review text into a text file, I add $ marks around the inline LaTeX and convert to PDF. Just reading the reviews is easier when the math and format is clear.\nConverting to PDF is as simple as:\npandoc response.txt -o response.pdf\nThen, following Matt Might‚Äôs workflow, I indent each reviewer response with a &gt; and prepare our replies underneath each item.\nWe were fortunate in that one reviewer offered a list of polite, meticulously detailed points. However, when converting our responses to PDF, the only difference between regular text and the LaTeX quote environment is increased indentation. When most of a document is normal text with only a few quotes, this is reasonable. But in our case it is very difficult to see, by indentation alone, exactly which text is the reviewer‚Äôs comment and which text is our rebuttal.\nAfter far too many hours digging through LaTeX and pandoc discussion forums and a long process of trial and error, I finally came up with the right commands to alter the quote environment. Simply include these lines at the beginning of your markdown file, and pandoc will apply the LaTeX code when converting to pdf.\n\\let\\quoteOld\\quote\n\\let\\endquoteOld\\endquote\n\\renewenvironment{quote}{\\quoteOld\\itshape}{\\endquoteOld}\nYou can save the above lines in a file called preamble.tex that you can then include in the LaTeX header with the pandoc --include-in-header argument.\npandoc --include-in-header preamble.tex response.txt -o response.pdf\nRather than remember to include this code every time you want italicized block quotes, you can download the pandoc default.latex template file, rename it something memorable ‚Äì like italicquotes.tex ‚Äì and add the above code somewhere near the top. (Somewhere after the first string of \\usepackage commands is probably best.)\nThen, copy the italicquotes.tex to the pandoc templates folder, which I found in the following folder:\ncp italicquotes.tex /usr/local/share/pandoc-1.11.1/data/templates/\nTo use this template, simply add --template=italicquotes.tex when you call pandoc:\npandoc -N --template=italicquotes.tex response.txt -o response.pdf\nOr, with fancy fonts:\npandoc -N --template=italicquotes.tex \\\n          --variable mainfont=Georgia \\\n          --variable sansfont=Arial \\\n          --variable fontsize=12pt \\\n          response.txt --latex-engine=xelatex -o response.pdf"
  },
  {
    "objectID": "blog/quote-albert-einstein/index.html",
    "href": "blog/quote-albert-einstein/index.html",
    "title": "Quote: Albert Einstein",
    "section": "",
    "text": "Every day I remind myself that my inner and outer life are based on the labors of other people, living and dead, and that I must exert myself in order to give in the same measure as I have received and am still receiving.\n‚Äî Albert Einstein"
  },
  {
    "objectID": "blog/presenting-smart-home-activity-profiles-at-informs-2017/index.html",
    "href": "blog/presenting-smart-home-activity-profiles-at-informs-2017/index.html",
    "title": "Presenting Smart Home Activity Profiles at INFORMS 2017",
    "section": "",
    "text": "I had a great time connecting with old and new friends and colleagues this past week at the INFORMS 2017 Annual Meeting.\nI was happy to have been invited by Julie Hammett to present in the Remote Patient Monitoring and mHealth Applications session Wednesday afternoon.\nFor those who are interested or couldn‚Äôt make the session due to timing, I‚Äôve posted a copy of my slides ‚Äì Occupant Activity Profiles from Smart Home Sensor Event Streams ‚Äì for you.\nSome of the highlights from this INFORMS include:\n\nDr.¬†Baraniuk‚Äôs talk on Deep Learning, especially his take on how we learn to train deep neural networks.\n\n\n;document.getElementById(\"tweet-46646\").innerHTML = tweet[\"html\"];\nThe INFORMS Chapter of USF winning Summa Cum Laude by continuing events and programs that I worked on as President of the INFORMS chapter several years ago.\n\n\nSpending a night out in Houston on my birthday, reconnecting with friends who have graduated.\nUsing Houston‚Äôs bike share system to get around.\nAnd all of the many conversations I had with other graduate students.\n\nThanks INFORMS and Houston for a great trip!"
  },
  {
    "objectID": "blog/go-postal-sunset/index.html",
    "href": "blog/go-postal-sunset/index.html",
    "title": "Go Postal Sunset",
    "section": "",
    "text": "Post office near my house"
  },
  {
    "objectID": "talk/xaringan-playground/index.html#abstract",
    "href": "talk/xaringan-playground/index.html#abstract",
    "title": "xaringan Playground",
    "section": "Abstract",
    "text": "Abstract\n\nxaringan is a quirky package that extends R Markdown to create beautiful web-based HTML slides. Some of xaringan‚Äôs quirks come from the JavaScript library it uses, remarkjs, and some of it from the unusual naming scheme xaringan uses for its functions. But under this quirky exterior lies a powerful tool for learning and practicing web development, especially when combined with infinite_moon_reader() for immediate feedback. In this talk I‚Äôll cover some basic web concepts that illustrate how fun and rewarding it can to learn HTML, CSS and JavaScript while building awesome slides in R Markdown."
  },
  {
    "objectID": "talk/seamless-epoxy/index.html#abstract",
    "href": "talk/seamless-epoxy/index.html#abstract",
    "title": "Seamless data-driven reporting with {epoxy}",
    "section": "Abstract",
    "text": "Abstract\n\n{epoxy} is a new R package that allows report authors to seamless blend prose and data in markdown, HTML, and LaTeX reports. {epoxy} builds on the excellent tools for data-driven reporting provided by R Markdown, Quarto and Shiny, while saving report authors from tedious and repetitive data formatting tasks. This talk will highlight the many ways that {epoxy} can help data scientists in medicine to streamline reports, articles, and Shiny apps."
  },
  {
    "objectID": "talk/extra-special-xaringan/index.html#abstract",
    "href": "talk/extra-special-xaringan/index.html#abstract",
    "title": "Your Slides are So Extra!",
    "section": "Abstract",
    "text": "Abstract\n\nThe xaringan package by Yihui Xie lets R users and R Markdown authors easily blend data, text, plots and htmlwidgets into beautiful HTML presentations that look great on the web, in print, and on screens. This lightning talk will highlight a new package for customizing and enhancing xaringan slides: xaringanExtra. This package provides a collection of extensions for xaringan presentations including a tiled slide overview, editable slides, embedded webcam, tabbed panels, slide change sounds, and more. Add something special to your next xaringan presentation with xaringanExtra."
  },
  {
    "objectID": "talk/epoxy-super-glue/index.html#abstract",
    "href": "talk/epoxy-super-glue/index.html#abstract",
    "title": "{epoxy}",
    "section": "Abstract",
    "text": "Abstract\nR Markdown, Quarto, and Shiny are powerful frameworks that allow authors to create data-driven reports and apps. Authors blend prose and data, without having to copy and paste results. This is fantastic! But truly excellent reports require a lot of work in the final inch to get numerical and stylistic formatting just right.\n{epoxy} is a new package that uses {glue} to give authors templating super powers. First, authors can use epoxy chunks to write sentences or paragraphs in markdown with glue-like inline variables. Then, they can use inline formatting for common numerical or character transformations.\nEpoxy works in R Markdown and Quarto, in markdown, LaTeX and HTML outputs. It also provides easy templating for Shiny apps for dynamic data-driven reporting. Beyond epoxy‚Äôs features, this talk will also touch on tips and approaches for data-driven reporting that will be useful to a wide audience, from R Markdown experts to the Quarto and Shiny curious."
  },
  {
    "objectID": "talk/bslib-modern-dashboards/index.html#abstract",
    "href": "talk/bslib-modern-dashboards/index.html#abstract",
    "title": "Achieving Concurrency in Streamlit with a RQ scheduler, Building Responsive Data Applications",
    "section": "",
    "text": "With increasing adoption of Streamlit to create interactive data applications in the usage of generative AI technologies, a challenge of maintaining responsiveness under heavy or concurrent user interactions has emerged as applications grow in complexity, sometimes with a long-running background job. This is where integrating task queueing systems like Redis Queue (RQ) into Streamlit applications can come in handy.\nIn this talk, we will explore how we can enable this integration between RQ and Streamlit to achieve concurrency, improve user experiences and effectively manage long-running tasks."
  },
  {
    "objectID": "project/xaringanExtra/index.html",
    "href": "project/xaringanExtra/index.html",
    "title": "üé° xaringanExtra",
    "section": "",
    "text": "Redirecting to https://pkg.garrickadenbuie.com/xaringanExtra‚Ä¶"
  },
  {
    "objectID": "project/sqrrl/index.html",
    "href": "project/sqrrl/index.html",
    "title": "üêøÔ∏è Sqrrl",
    "section": "",
    "text": "UPDATE 10/17/2017: Don‚Äôt use this! I made it for myself so it works for what I needed it for. But you probably shouldn‚Äôt use this package. There are better ways of building SQL queries that are safer and better (and probably even easier). For now, let me just point you in the direction of db.rstudio.com, dplyr/dbplyr, and the recently added glue_sql() function in the glue package.\nProject Links: source, documentation\nsqrrl is a small collection of utility functions that help build text-based SQL queries in an R-style native-feeling and functional manner.\nUnlike other packages that build SQL queries using an object-oriented style, sqrrl provides small functions that produce SQL snippets and can be linked together to compose SQL queries. The result is that the code to produce the SQL statement reads much like the SQL statement iteself. On the other hand, sqrrl doesn‚Äôt know anything about your database and can‚Äôt help you out with completions, etc.\nWhere this package is most useful is with Shiny web apps that interact with a MySQL backend. The utilities are all built so that queries can be built using column names and values stored inside ordinary R data structures.\nThe following is a quick demonstration of how the package works using the nyclights13 dataset. For more information on sqrrl, check out the package documentation."
  },
  {
    "objectID": "project/sqrrl/index.html#setup-flights-database",
    "href": "project/sqrrl/index.html#setup-flights-database",
    "title": "üêøÔ∏è Sqrrl",
    "section": "Setup flights database",
    "text": "Setup flights database\nTo demonstrate the features in sqrrl, let‚Äôs set up an in-memory SQLite database using the nycflights13 dataset featured in dplyr and dbplyr.\nFirst, load (or install) the pacakges and functions that we need.\n\n# ---- Workspace Setup ----\nlibrary('nycflights13') # install.packages('nycflights13')\nlibrary('DBI')          # install.packages('DBI')\nlibrary('dplyr')        # install.packages('dplyr')\nlibrary('dbplyr')       # install.packages('dbplyr')\n\n# Load the sqrrl package\n# devtools::isntall_github('gadenbuie/sqrrl')\nlibrary('sqrrl')\n\n# Alias to create nice tables\nas_table &lt;- function(...) knitr::kable(..., format = 'html')\n\nThen load the flights data frame from nycflights13 into the in-memory SQLite database (this code comes direclty from the dbplyr documentation).\n\n# ---- Example Setup ----\n# Create an in-memory SQLite database\ncon &lt;- dbConnect(RSQLite::SQLite(), path = \":memory:\")\n\n# Use dplyr/dbplyr to copy flights table to the temp db\ncopy_to(con, nycflights13::flights, \"flights\",\n  temporary = FALSE,\n  indexes = list(\n    c(\"year\", \"month\", \"day\"),\n    \"carrier\",\n    \"tailnum\",\n    \"dest\"\n  )\n)\n\n# Show first 5 rows\ndbGetQuery(con, 'SELECT * FROM flights LIMIT 5') %&gt;%\n  as_table\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\n\n\n2013\n1\n1\n517\n515\n2\n830\n819\n11\nUA\n1545\nN14228\nEWR\nIAH\n227\n1400\n5\n15\n1357034400\n\n\n2013\n1\n1\n533\n529\n4\n850\n830\n20\nUA\n1714\nN24211\nLGA\nIAH\n227\n1416\n5\n29\n1357034400\n\n\n2013\n1\n1\n542\n540\n2\n923\n850\n33\nAA\n1141\nN619AA\nJFK\nMIA\n160\n1089\n5\n40\n1357034400\n\n\n2013\n1\n1\n544\n545\n-1\n1004\n1022\n-18\nB6\n725\nN804JB\nJFK\nBQN\n183\n1576\n5\n45\n1357034400\n\n\n2013\n1\n1\n554\n600\n-6\n812\n837\n-25\nDL\n461\nN668DN\nLGA\nATL\n116\n762\n6\n0\n1357038000"
  },
  {
    "objectID": "project/sqrrl/index.html#querying-flights",
    "href": "project/sqrrl/index.html#querying-flights",
    "title": "üêøÔ∏è Sqrrl",
    "section": "Querying flights",
    "text": "Querying flights\nOften, when I‚Äôm working with a database, I‚Äôll create an alias for dbGetQuery with the database or table name. Inside the alias function I usually add any data type modifications that might need to be applied, and I suppress the warning messages that DBI outputs about data type conversions.\n\nflights &lt;- function(query, ...) {\n  suppressWarnings(dbGetQuery(con, query, ...))\n}\n\nNow we can repeat the above SELECT statement using sqrrl, this time limiting the columns selected.\n\nflight_cols &lt;- c('year', 'month', 'day',\n                 'carrier', 'flight', 'tailnum')\nSELECT(flight_cols) %+%\n  FROM('flights') %+%\n  LIMIT(5) %&gt;%\n  flights %&gt;%\n  as_table\n\n\n\n\nyear\nmonth\nday\ncarrier\nflight\ntailnum\n\n\n\n\n2013\n1\n1\nUA\n1545\nN14228\n\n\n2013\n1\n1\nUA\n1714\nN24211\n\n\n2013\n1\n1\nAA\n1141\nN619AA\n\n\n2013\n1\n1\nB6\n725\nN804JB\n\n\n2013\n1\n1\nDL\n461\nN668DN\n\n\n\n\n\nNote that sqrrl provides the %+% infix operator, which is essentially just an alias for paste(x, y).\n\n'a' %+% 'b'\n\n[1] \"a b\"\n\n# or PHP style without a padded space: paste0\n'a' %.% 'b'\n\n[1] \"ab\"\n\n\nWe can also do more complicated queries, like finding the average arrival delay, grouped by tail number:\n\nSELECT('tailnum', delay = 'avg(arr_delay)', n = 'count(*)') %+%\n  FROM('flights') %+%\n  GROUP_BY('tailnum') %+%\n  ORDER_BY(DESC('delay')) %+%\n  LIMIT(10) %&gt;%\n  flights %&gt;%\n  as_table\n\n\n\n\ntailnum\ndelay\nn\n\n\n\n\nN844MH\n320.0000\n1\n\n\nN911DA\n294.0000\n1\n\n\nN922EV\n276.0000\n1\n\n\nN587NW\n264.0000\n1\n\n\nN851NW\n219.0000\n1\n\n\nN928DN\n201.0000\n1\n\n\nN7715E\n188.0000\n1\n\n\nN654UA\n185.0000\n1\n\n\nN665MQ\n174.6667\n6\n\n\nN427SW\n157.0000\n1\n\n\n\n\n\nsqrrl also provides a wrapper around the python utility sqlformat that can be used to pretty-print SQL formats.\n\nSELECT('tailnum', delay = 'avg(arr_delay)', n = 'count(*)') %+%\n  FROM('flights') %+%\n  GROUP_BY('tailnum') %+%\n  ORDER_BY(DESC('delay')) %+%\n  LIMIT(10) %&gt;%\n  sqlformat %&gt;% cat\nSELECT tailnum,\n       avg(arr_delay) AS delay,\n       count(*) AS n\n  FROM flights\n GROUP BY tailnum\n ORDER BY delay DESC\n LIMIT 10\n\nLet‚Äôs use the above as an inner query and filter on n &gt; 100:\n\nquery_all_arr_delay &lt;- SELECT(\n  'tailnum', delay = 'avg(arr_delay)', n = 'count(*)'\n) %+%\n  FROM('flights') %+%\n  GROUP_BY('tailnum') %+%\n  ORDER_BY(DESC('delay'))\n\nSELECT() %+%\n  FROM(delay = parens(query_all_arr_delay)) %+%\n  WHERE(gt(n = 100)) %+%\n  LIMIT(10) %&gt;%\n  flights %&gt;%\n  as_table\n\n\n\n\ntailnum\ndelay\nn\n\n\n\n\nN11119\n30.30657\n148\n\n\nN16919\n29.88745\n251\n\n\nN14998\n27.92202\n230\n\n\nN15910\n27.61132\n280\n\n\nN13123\n25.97345\n121\n\n\nN11192\n25.85235\n154\n\n\nN14950\n25.28780\n219\n\n\nN21130\n24.96610\n126\n\n\nN24128\n24.91803\n129\n\n\nN22971\n24.74766\n230"
  },
  {
    "objectID": "project/sqrrl/index.html#queries-are-just-strings",
    "href": "project/sqrrl/index.html#queries-are-just-strings",
    "title": "üêøÔ∏è Sqrrl",
    "section": "Queries are just strings",
    "text": "Queries are just strings\nNotice that unlike other packages, sqrrl can‚Äôt build the nested queries for you. You still need to understand the structure of the database and the structure of the query.\nBut when compared with the final output of the query, the sqrrl version looks a lot like SQL transliterated into R functions.\n\nSELECT() %+%\n  FROM(delay = parens(\n    SELECT('tailnum', delay = 'avg(arr_delay)', n = 'count(*)') %+%\n      FROM('flights') %+%\n      GROUP_BY('tailnum') %+%\n      ORDER_BY(DESC('delay'))\n  )) %+%\n  WHERE(gt(n = 100)) %+%\n  LIMIT(10) %&gt;%\n  sqlformat() %&gt;%\n  cat()\nSELECT *\n  FROM (\n        SELECT tailnum,\n               avg(arr_delay) AS delay,\n               count(*) AS n\n          FROM flights\n         GROUP BY tailnum\n         ORDER BY delay DESC\n       ) delay\n WHERE n&gt;100\n LIMIT 10\n\nFor me, at least, where the goal is to write SQL queries as bare strings, sqrrl lets me write in R and think in SQL without having to add a huge number of paste and paste0 functions.\nEverything in sqrrl takes input data from regular R data types and outputs an SQL snippet.\nFor an example of nearly everything each of the functions can do, see the Getting Started section in the documentation."
  },
  {
    "objectID": "project/sqrrl/index.html#a-more-complicated-select-query",
    "href": "project/sqrrl/index.html#a-more-complicated-select-query",
    "title": "üêøÔ∏è Sqrrl",
    "section": "A more complicated SELECT query",
    "text": "A more complicated SELECT query\nAs a final example, here is a fully-loaded select query.\n\nSELECT('`year`', 'carrier', 'flight', 'dest',\n       n = 'count(*)',\n       avg_dist = 'avg(distance)',\n       avg_air_time = 'avg(air_time)') %+%\n  FROM(f = 'flights') %+%\n  WHERE(\n    BETWEEN('month', 6, 12),\n    'carrier' %IN% c(\"UA\", \"AA\", \"US\", \"WN\"),\n    geq('dep_time' = 800),\n    leq('air_time' = 120),\n    'origin' %LIKE% 'JFK'\n  ) %+%\n  GROUP_BY('`year`', 'carrier', 'flight', 'dest') %+%\n  ORDER_BY(DESC('n')) %+%\n  LIMIT(10) %&gt;%\n  { sqlformat(.) %&gt;% cat; . } %&gt;%\n  flights %&gt;%\n  as_table\nSELECT `year`,\n       carrier,\n       flight,\n       dest,\n       count(*) AS n,\n       avg(distance) AS avg_dist,\n       avg(air_time) AS avg_air_time\n  FROM flights f\n WHERE `month` BETWEEN 6 AND 12\n   AND carrier IN (\"UA\", \"AA\", \"US\", \"WN\")\n   AND dep_time&gt;=800\n   AND air_time&lt;=120\n   AND origin LIKE(\"JFK\")\n GROUP BY `year`,\n          carrier,\n          flight,\n          dest\n ORDER BY n DESC\n LIMIT 10\n\n\n\n\nyear\ncarrier\nflight\ndest\nn\navg_dist\navg_air_time\n\n\n\n\n2013\nUS\n1831\nCLT\n178\n541\n86.95506\n\n\n2013\nUS\n425\nCLT\n126\n541\n84.92857\n\n\n2013\nAA\n178\nBOS\n119\n187\n37.94118\n\n\n2013\nAA\n256\nBOS\n117\n187\n39.13675\n\n\n2013\nAA\n2314\nBOS\n115\n187\n37.85217\n\n\n2013\nUS\n1802\nCLT\n112\n541\n87.23214\n\n\n2013\nAA\n84\nBOS\n101\n187\n37.95049\n\n\n2013\nAA\n1850\nBOS\n94\n187\n38.46809\n\n\n2013\nAA\n1838\nBOS\n93\n187\n37.83871\n\n\n2013\nAA\n1762\nBOS\n86\n187\n38.47674\n\n\n\n\n\nThis query and table select the most popular flights from JFK between June and December of 2013 from the carriers UA, AA, US, and WN that depart JFK after 8:00 AM and have an air time of less than 2 hours."
  },
  {
    "objectID": "project/sqrrl/index.html#learn-more",
    "href": "project/sqrrl/index.html#learn-more",
    "title": "üêøÔ∏è Sqrrl",
    "section": "Learn more",
    "text": "Learn more\nThere‚Äôs more that the package can do, like JOINs, INSERTs, and UPDATEs that I haven‚Äôt gone into here.\nThere are also a number of wrappers, comparison operators and concatenators that can be used for wrapping strings in quotes ‚Äî e.g.¬†quotes() ‚Äî comparing columns to values ‚Äî e.g.¬†geq(), eq(), lt(), neq() ‚Äî and stringing together statements ‚Äî e.g.¬†AND(), OR(), %LIKE%, %IN%, BETWEEN().\nThere‚Äôs an example of nearly every single function and each of it‚Äôs possible configurations in the package documentation.\nHopefully this package is useful to someone other than myself (like you!). If you run into any problems, let me know or submit an issue on GitHub."
  },
  {
    "objectID": "project/rsthemes/index.html",
    "href": "project/rsthemes/index.html",
    "title": "üîÆ rsthemes",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork"
  },
  {
    "objectID": "project/rsthemes/index.html#installation",
    "href": "project/rsthemes/index.html#installation",
    "title": "üîÆ rsthemes",
    "section": "Installation",
    "text": "Installation\nYou can install rsthemes from my r-universe with:\ninstall.packages(\n  \"rsthemes\",\n  repos = c(gadenbuie = 'https://gadenbuie.r-universe.dev', getOption(\"repos\"))\n)\nOr you can install rsthemes from GitHub with:\n# install.packages(\"devtools\")\ndevtools::install_github(\"gadenbuie/rsthemes\")\nThen, install the included, hand-crafted themes with:\nrsthemes::install_rsthemes()\nor you can install the themes plus an additional set of base16-based themes with\nrsthemes::install_rsthemes(include_base16 = TRUE)"
  },
  {
    "objectID": "project/rsthemes/index.html#usage",
    "href": "project/rsthemes/index.html#usage",
    "title": "üîÆ rsthemes",
    "section": "Usage",
    "text": "Usage\nThe rsthemes package includes a couple helper functions for exploring the themes.\n# list installed themes\nrsthemes::list_rsthemes()\n\n# Try all themes\nrsthemes::try_rsthemes()\n\n# Try just the light, dark, or base16 themes, e.g.\nrsthemes::try_rsthemes(\"light\")\nUse rstudioapi::applyTheme() to activate a theme from the R console, or use Tools &gt; Global Options &gt; Appearance to interactively select a theme.\n# Use a theme\nrstudioapi::applyTheme(\"One Dark {rsthemes}\")"
  },
  {
    "objectID": "project/rsthemes/index.html#easy-theme-switching",
    "href": "project/rsthemes/index.html#easy-theme-switching",
    "title": "üîÆ rsthemes",
    "section": "Easy Theme Switching",
    "text": "Easy Theme Switching\nrsthemes includes RStudio addins and functions to‚Ä¶ \n\nüåÖ Toggle Dark ModeSwitch between two preferred dark and light themes\nüåÉ Auto Dark ModeAutomatically choose a dark or light theme by time of day\n‚ù§Ô∏è Favorite ThemesSwitch between a few of your favorite themes\nü•± Use Default RStudio ThemeSwitch back to RStudio‚Äôs default theme\n\n\nChoose Your Preferred Themes\nFirst, set a default light and dark theme. For your current R sessions, you can use the Set Default Light Theme to Current addin (or the corresponding dark theme addin), or you can call the set_theme_light() or set_theme_dark() functions:\n# Set current theme to default light or dark theme\nrsthemes::set_theme_light()\nrsthemes::set_theme_dark()\n\n# Set a specific theme to default light or dark theme\nrsthemes::set_theme_light(\"One Light {rsthemes}\")\nrsthemes::set_theme_dark(\"One Dark {rsthemes}\")\nTo create a list of your favorite themes, you can use set_theme_favorite().\n# Add current theme to your list of favorites\nrsthemes::set_theme_favorite()\n\n# Add a list of themes to your favorites\nrsthemes::set_theme_favorite(\n  c(\"GitHub {rsthemes}\", \"One Light {rsthemes}\", \"One Dark {rsthemes}\")\n)\nThese functions only save your preferences for the current R session. To set these defaults for all R sessions, add your preferences to your ~/.Rprofile. (You can use usethis::edit_r_profile() to quickly open your ~/.Rprofile for editing.)\n# ~/.Rprofile\nif (interactive()) {\n  rsthemes::set_theme_light(\"GitHub {rsthemes}\")\n  rsthemes::set_theme_dark(\"Fairyfloss {rsthemes}\")\n  rsthemes::set_theme_favorite(\n    c(\"GitHub {rsthemes}\", \n      \"One Light {rsthemes}\", \n      \"One Dark {rsthemes}\")\n  )\n}\nYou can also set the following global options directly.\n# ~/.Rprofile\noptions(\n  rsthemes.theme_light = \"Nord Snow Storm {rsthemes}\",\n  rsthemes.theme_dark = \"Nord Polar Night Aurora {rsthemes}\",\n  rsthemes.theme_favorite = paste(\"One\", c(\"Light\", \"Dark\"), \"{rsthemes}\")\n)\n\n\nToggle Your Favorite Themes\nUse the Next Favorite Theme addin to walk through your list of favorite themes. Use the Modify Keyboard Shortcuts‚Ä¶ dialog in the Tools menu of RStudio to create a keyboard shortcut to make it easy to quickly switch themes ‚Äî I use Ctrl+ Alt + N. You can also manually call use_theme_favorite() to use the next theme in the your favorites list.\nEach time you run the addin, RStudio switches to the next theme in your favorites list. This is great if you have a few themes that you use in various contexts. For example, I have my personal favorite themes plus a few themes that work well during class or presentation sessions.\n\n\nAutomatic or Manual Light/Dark Mode\nUse the Toggle Dark Mode addin to switch between your default light and dark themes. You can even set a keyboard shortcut in RStudio ‚Äî I used Ctrl + Alt + D ‚Äî to toggle dark mode.\nYou can also automatically choose the dark or light theme by time of day, using the included Auto Choose Dark or Light Theme addin, which requires that you‚Äôve set your preferred light/dark themes (see above).\nIf you would like to automatically choose the dark or light theme by time of day during each new session, you can call rsthemes::use_theme_auto() in your ~/.Rprofile. For best results, use the following template in your ~/.Rprofile to declare your preferred dark and light themes and to choose the correct style when your R session reloads.\nif (interactive() && requireNamespace(\"rsthemes\", quietly = TRUE)) {\n  # Set preferred themes if not handled elsewhere..\n  rsthemes::set_theme_light(\"One Light {rsthemes}\")  # light theme\n  rsthemes::set_theme_dark(\"One Dark {rsthemes}\") # dark theme\n\n  # Whenever the R session restarts inside RStudio...\n  setHook(\"rstudio.sessionInit\", function(isNewSession) {\n    # Automatically choose the correct theme based on time of day\n    rsthemes::use_theme_auto(dark_start = \"18:00\", dark_end = \"6:00\")\n  }, action = \"append\")\n}\n\n\nGo Back to the Default\nSometimes when you‚Äôre teaching or demonstrating RStudio features, you‚Äôd like to have your IDE match the appearance of your learners, or at least the basic theme that everyone starts out with when they install RStudio for the first time.\nUse the Use Default RStudio Theme to quickly switch back to RStudio‚Äôs default theme, Textmate. Or, you can use rsthemes::use_default_rstudio_theme() to initiate the switch, perhaps from within the .Rprofile file of your teaching project."
  },
  {
    "objectID": "project/rsthemes/index.html#uninstall",
    "href": "project/rsthemes/index.html#uninstall",
    "title": "üîÆ rsthemes",
    "section": "Uninstall",
    "text": "Uninstall\nIf you want to uninstall all or some of the themes, you can use\nrsthemes::remove_rsthemes()\n\n# or just the base16 themes, e.g.\nrsthemes::remove_rsthemes(\"base16\")"
  },
  {
    "objectID": "project/rsthemes/index.html#thanks-and-theme-credits",
    "href": "project/rsthemes/index.html#thanks-and-theme-credits",
    "title": "üîÆ rsthemes",
    "section": "Thanks and Theme Credits",
    "text": "Thanks and Theme Credits\n\nPalettes\n\nbase16 (Various Authors)\nFairyfloss (Amy Wibowo (sailorhg))\nFlat White (Dmitry Biletskyy)\nNord (Sven Greb)\nOceanic Plus (Marco Scannadinari)\nAtom One Dark\nAtom One Light\nSolarized (Ethan Schoonover)\nHorizon Dark (Jonathan Olaleye)\na11y-syntax-highlighting (Eric Bailey)\nNight Owl (Sarah Drasner)\n\nwith huge thanks to original Night Owlish implementation in RStudio by Mara Averick\n\nYule RStudio\n\nBased on the Yule tmTheme\nPorted from gadenbuie/yule-rstudio\nFeaturing a background image by Joanna Kosinska\n\nMaterial Theme\n\nContributed to rsthemes by Zac de Lusignan\n\nSerendipity (wickedtemplates)"
  },
  {
    "objectID": "project/shrtcts/index.html",
    "href": "project/shrtcts/index.html",
    "title": "üç∞ shrtcts",
    "section": "",
    "text": "Redirecting to https://pkg.garrickadenbuie.com/shrtcts‚Ä¶"
  },
  {
    "objectID": "project/tidyexplain/index.html",
    "href": "project/tidyexplain/index.html",
    "title": "ü§π tidyexplain",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork\n\nMutating Joins ‚Äî inner_join(), left_join(), right_join(), full_join()\nFiltering Joins ‚Äî semi_join(), anti_join()\nSet Operations ‚Äî union(), union_all(), intersect(), setdiff()\nTidy Data ‚Äî pivot_wider() and pivot_longer(), spread() and gather()\nLearn more about\n\nUsing the animations and images\nRelational Data\ngganimate"
  },
  {
    "objectID": "project/tidyexplain/index.html#tidy-animated-verbs",
    "href": "project/tidyexplain/index.html#tidy-animated-verbs",
    "title": "ü§π tidyexplain",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork\n\nMutating Joins ‚Äî inner_join(), left_join(), right_join(), full_join()\nFiltering Joins ‚Äî semi_join(), anti_join()\nSet Operations ‚Äî union(), union_all(), intersect(), setdiff()\nTidy Data ‚Äî pivot_wider() and pivot_longer(), spread() and gather()\nLearn more about\n\nUsing the animations and images\nRelational Data\ngganimate"
  },
  {
    "objectID": "project/tidyexplain/index.html#background",
    "href": "project/tidyexplain/index.html#background",
    "title": "ü§π tidyexplain",
    "section": "Background",
    "text": "Background\n\nUsage\nPlease feel free to use these images for teaching or learning about action verbs from the tidyverse. You can directly download the original animations or static images in svg or png formats, or you can use the scripts to recreate the images locally.\nCurrently, the animations cover the dplyr two-table verbs and I‚Äôd like to expand the animations to include more verbs from the tidyverse. Suggestions are welcome!\n\n\nRelational Data\nThe Relational Data chapter of the R for Data Science book by Garrett Grolemund and Hadley Wickham is an excellent resource for learning more about relational data.\nThe dplyr two-table verbs vignette and Jenny Bryan‚Äôs Cheatsheet for dplyr join functions are also great resources.\n\n\ngganimate\nThe animations were made possible by the newly re-written gganimate package by Thomas Lin Pedersen (original by Dave Robinson). The package readme provides an excellent (and quick) introduction to gganimate.\n\n\nDynamic Animations\nThanks to an initial push by David Zimmermann, we have begun work towards functions that generate dynamic animations from users‚Äô actual data. Please visit the pkg branch of the tidyexplain repository for more information (or to contribute!)."
  },
  {
    "objectID": "project/tidyexplain/index.html#mutating-joins",
    "href": "project/tidyexplain/index.html#mutating-joins",
    "title": "ü§π tidyexplain",
    "section": "Mutating Joins",
    "text": "Mutating Joins\n\nA mutating join allows you to combine variables from two tables. It first matches observations by their keys, then copies across variables from one table to the other.\nR for Data Science: Mutating joins\n\n\nx\n#&gt; # A tibble: 3 √ó 2\n#&gt;      id x    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     1 x1   \n#&gt; 2     2 x2   \n#&gt; 3     3 x3\ny\n#&gt; # A tibble: 3 √ó 2\n#&gt;      id y    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     1 y1   \n#&gt; 2     2 y2   \n#&gt; 3     4 y4\n\nInner Join\n\nAll rows from x where there are matching values in y, and all columns from x and y.\n\n\ninner_join(x, y, by = \"id\")\n#&gt; # A tibble: 2 √ó 3\n#&gt;      id x     y    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2\n\n\nLeft Join\n\nAll rows from x, and all columns from x and y. Rows in x with no match in y will have NA values in the new columns.\n\n\nleft_join(x, y, by = \"id\")\n#&gt; # A tibble: 3 √ó 3\n#&gt;      id x     y    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     3 x3    &lt;NA&gt;\n\n\nLeft Join (Extra Rows in y)\n\n‚Ä¶ If there are multiple matches between x and y, all combinations of the matches are returned.\n\n\ny_extra # has multiple rows with the key from `x`\n#&gt; # A tibble: 4 √ó 2\n#&gt;      id y    \n#&gt;   &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 y1   \n#&gt; 2     2 y2   \n#&gt; 3     4 y4   \n#&gt; 4     2 y5\nleft_join(x, y_extra, by = \"id\")\n#&gt; # A tibble: 4 √ó 3\n#&gt;      id x     y    \n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     2 x2    y5   \n#&gt; 4     3 x3    &lt;NA&gt;\n\n\nRight Join\n\nAll rows from y, and all columns from x and y. Rows in y with no match in x will have NA values in the new columns.\n\n\nright_join(x, y, by = \"id\")\n#&gt; # A tibble: 3 √ó 3\n#&gt;      id x     y    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     4 &lt;NA&gt;  y4\n\n\nFull Join\n\nAll rows and all columns from both x and y. Where there are not matching values, returns NA for the one missing.\n\n\nfull_join(x, y, by = \"id\")\n#&gt; # A tibble: 4 √ó 3\n#&gt;      id x     y    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     3 x3    &lt;NA&gt; \n#&gt; 4     4 &lt;NA&gt;  y4"
  },
  {
    "objectID": "project/tidyexplain/index.html#filtering-joins",
    "href": "project/tidyexplain/index.html#filtering-joins",
    "title": "ü§π tidyexplain",
    "section": "Filtering Joins",
    "text": "Filtering Joins\n\nFiltering joins match observations in the same way as mutating joins, but affect the observations, not the variables. ‚Ä¶ Semi-joins are useful for matching filtered summary tables back to the original rows. ‚Ä¶ Anti-joins are useful for diagnosing join mismatches.\nR for Data Science: Filtering Joins\n\n\nSemi Join\n\nAll rows from x where there are matching values in y, keeping just columns from x.\n\n\nsemi_join(x, y, by = \"id\")\n#&gt; # A tibble: 2 √ó 2\n#&gt;      id x    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     1 x1   \n#&gt; 2     2 x2\n\n\nAnti Join\n\nAll rows from x where there are not matching values in y, keeping just columns from x.\n\n\nanti_join(x, y, by = \"id\")\n#&gt; # A tibble: 1 √ó 2\n#&gt;      id x    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     3 x3"
  },
  {
    "objectID": "project/tidyexplain/index.html#set-operations",
    "href": "project/tidyexplain/index.html#set-operations",
    "title": "ü§π tidyexplain",
    "section": "Set Operations",
    "text": "Set Operations\n\nSet operations are occasionally useful when you want to break a single complex filter into simpler pieces. All these operations work with a complete row, comparing the values of every variable. These expect the x and y inputs to have the same variables, and treat the observations like sets.\nR for Data Science: Set operations\n\n\nx\n#&gt; # A tibble: 3 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a    \n#&gt; 2 1     b    \n#&gt; 3 2     a\ny \n#&gt; # A tibble: 2 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a    \n#&gt; 2 2     b\n\nUnion\n\nAll unique rows from x and y.\n\n\nunion(x, y)\n#&gt; # A tibble: 4 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a    \n#&gt; 2 1     b    \n#&gt; 3 2     a    \n#&gt; 4 2     b\n\nunion(y, x)\n#&gt; # A tibble: 4 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a    \n#&gt; 2 2     b    \n#&gt; 3 1     b    \n#&gt; 4 2     a\n\n\nUnion All\n\nAll rows from x and y, keeping duplicates.\n\n\nunion_all(x, y)\n#&gt; # A tibble: 5 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a    \n#&gt; 2 1     b    \n#&gt; 3 2     a    \n#&gt; 4 1     a    \n#&gt; 5 2     b\n\n\nIntersection\n\nCommon rows in both x and y, keeping just unique rows.\n\n\nintersect(x, y)\n#&gt; # A tibble: 1 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a\n\n\nSet Difference\n\nAll rows from x which are not also rows in y, keeping just unique rows.\n\n\nsetdiff(x, y)\n#&gt; # A tibble: 2 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     b    \n#&gt; 2 2     a\n\nsetdiff(y, x)\n#&gt; # A tibble: 1 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 2     b"
  },
  {
    "objectID": "project/tidyexplain/index.html#tidy-data",
    "href": "project/tidyexplain/index.html#tidy-data",
    "title": "ü§π tidyexplain",
    "section": "Tidy Data",
    "text": "Tidy Data\nTidy data follows the following three rules:\n\nEach variable has its own column.\nEach observation has its own row.\nEach value has its own cell.\n\nMany of the tools in the tidyverse expect data to be formatted as a tidy dataset and the tidyr package provides functions to help you organize your data into tidy data.\n\nwide\n#&gt; # A tibble: 2 √ó 4\n#&gt;      id x     y     z    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 a     c     e    \n#&gt; 2     2 b     d     f\nlong\n#&gt; # A tibble: 6 √ó 3\n#&gt;      id key   val  \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x     a    \n#&gt; 2     2 x     b    \n#&gt; 3     1 y     c    \n#&gt; 4     2 y     d    \n#&gt; 5     1 z     e    \n#&gt; 6     2 z     f\n\nPivot Wider and Longer\npivot_wider() and pivot_longer() were introduced in tidyr version 1.0 (released in September 2019). They provide a more consistent and more powerful approach to changing the fundamental shape of the data and are ‚Äúmodern alternatives to spread() and gather().\nHere we show the very basic mechanics of pivoting, but there‚Äôs much more that the pivot functions can do. You can learn more about them in the Pivoting vignette in tidyr.\npivot_wider(data, names_from = key, values_from = val)\n\npivot_wider() ‚Äúwidens‚Äù data, increasing the number of columns and decreasing the number of rows.\n\npivot_longer(data, cols = x:y, names_to = \"key\", values_to = \"val\")\n\npivot_longer() ‚Äúlengthens‚Äù data, increasing the number of rows and decreasing the number of columns.\n\n\n\n\nSpread and Gather\nspread(data, key, value)\n\nSpread a key-value pair across multiple columns. Use it when an a column contains observations from multiple variables.\n\ngather(data, key = \"key\", value = \"value\", ...)\n\nGather takes multiple columns and collapses into key-value pairs, duplicating all other columns as needed. You use gather() when you notice that your column names are not names of variables, but values of a variable.\n\n\ngather(wide, key, val, x:z)\n#&gt; # A tibble: 6 √ó 3\n#&gt;      id key   val  \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x     a    \n#&gt; 2     2 x     b    \n#&gt; 3     1 y     c    \n#&gt; 4     2 y     d    \n#&gt; 5     1 z     e    \n#&gt; 6     2 z     f\nspread(long, key, val)\n#&gt; # A tibble: 2 √ó 4\n#&gt;      id x     y     z    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 a     c     e    \n#&gt; 2     2 b     d     f"
  },
  {
    "objectID": "project/xaringanthemer/index.html",
    "href": "project/xaringanthemer/index.html",
    "title": "üé® xaringanthemer",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork\nGive your xaringan slides some style with xaringanthemer within your slides.Rmd file without (much) CSS."
  },
  {
    "objectID": "project/xaringanthemer/index.html#installation",
    "href": "project/xaringanthemer/index.html#installation",
    "title": "üé® xaringanthemer",
    "section": "Installation",
    "text": "Installation\nxaringanthemer currently lives on GitHub.\n# install.packages(\"devtools\")\ndevtools::install_github(\"gadenbuie/xaringanthemer\")\nRead on for a quick overview, or read through the xaringanthemer documentation for more information."
  },
  {
    "objectID": "project/xaringanthemer/index.html#usage",
    "href": "project/xaringanthemer/index.html#usage",
    "title": "üé® xaringanthemer",
    "section": "Usage",
    "text": "Usage\n\nFirst, add the xaringan-themer.css file to the YAML header of your xaringan slides.\noutput:\n  xaringan::moon_reader:\n    lib_dir: libs\n    css: xaringan-themer.css\nThen, in a hidden chunk just after the knitr setup chunk, load xaringanthemer and try one of the theme functions.\n```{r xaringan-themer, include = FALSE}`r \"\"`\nlibrary(xaringanthemer)\nmono_light(\n  base_color = \"#1c5253\",\n  header_font_google = google_font(\"Josefin Sans\"),\n  text_font_google   = google_font(\"Montserrat\", \"300\", \"300i\"),\n  code_font_google   = google_font(\"Droid Mono\")\n)\n```\n\n\n\nxaringanthemer example with mono_light theme\n\n\n\nTab Completion\nxaringanthemer is Tab friendly ‚Äì use autocomplete to explore the template variables that you can adjust in each of the themes!\n\n\n\nxaringanthemer rstudio autocompletion example\n\n\n\n\nR Markdown Template in RStudio\nYou can also skip the above and just create a Ninja Themed Presentation from the New R Markdown Document menu in RStudio.\n\n\n\n\nrstudio xaringanthemer rmarkdown template\n\n\n\n\nxaringanthemer was built by Garrick Aden-Buie (@grrrck).\nBig thank you to Yihui Xie, especially for xaringan. Also thanks to Ole Petter Bang for remark.js.\nFeel free to file an issue if you find a bug or have a theme suggestion ‚Äì or better yet, submit a pull request!"
  },
  {
    "objectID": "talk/build-your-own-universe/index.html#abstract",
    "href": "talk/build-your-own-universe/index.html#abstract",
    "title": "Build Your Own Universe",
    "section": "Abstract",
    "text": "Abstract\n\nInstitutional honest brokers consolidate patient, clinical, and lab data from a variety of data sources in order to provide investigators with research-ready data sets. High-quality research data provisioning requires skilled navigation of heterogeneous software systems and a detailed understanding of data structure standards within each source. In this talk we discuss how we, as honest brokers at a large cancer center, have created a universe of internal R packages that simplify data access, store and present metadata, standardize best practices, support reproducibility and repeatability, apply branding styles to reports and visualizations, and facilitate communication with the research data end user. Our package ecosystem simplifies the workflow of honest brokers to scale curation and delivery of high-quality research data."
  },
  {
    "objectID": "talk/extra-great-slides-nyhackr/index.html#abstract",
    "href": "talk/extra-great-slides-nyhackr/index.html#abstract",
    "title": "Making Extra Great Slides",
    "section": "Abstract",
    "text": "Abstract\nThe xaringan package by YiHui Xie lets R users and R Markdown authors easily blend data, text, plots and htmlwidgets into beautiful HTML presentations that look great on the web, in print, and on screens.\nIn addition to demonstrating how to go from R Markdown to web-based slides with xaringan, in this talk I‚Äôll show you how to completely customize the appearance of your slides with xaringanthemer, a package that lets you quickly create a complete slide theme from only a few color choices.\nThen we‚Äôll go beyond appearances with a variety of addins and extensions from the xaringanExtra package, including: a tiled slide overview, editable slides, embedded webcam videos, tabbed panels, extra styles, shareable and embeddable slides, animations, and real time slide broadcasting."
  },
  {
    "objectID": "talk/extra-great-slides-nyhackr/index.html#packages",
    "href": "talk/extra-great-slides-nyhackr/index.html#packages",
    "title": "Making Extra Great Slides",
    "section": "Packages",
    "text": "Packages\n\nxaringan\nxaringanthemer\nxaringanExtra\nxaringanBuilder\nmetathis\n\n# On CRAN\ninstall.packages(\"xaringan\")\ninstall.packages(\"xaringanthemer\")\ninstall.packages(\"metathis\")\n\n# From GitHub\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/xaringanExtra\")\nremotes::install_github(\"jhelvy/xaringanBuilder\")\nremotes::install_github(\"gadenbuie/countdown\")"
  },
  {
    "objectID": "talk/index.html",
    "href": "talk/index.html",
    "title": "Invited Talks and Presentations",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAchieving Concurrency in Streamlit with a RQ scheduler, Building Responsive Data Applications\n\n\n\nConference\n\n\n\nTBD\n\n\n\n\n\nJun 1, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talk/sliding-in-style-south-coast-ma/index.html#abstract",
    "href": "talk/sliding-in-style-south-coast-ma/index.html#abstract",
    "title": "Sliding in Style",
    "section": "Abstract",
    "text": "Abstract\nThe xaringan package by YiHui Xie lets R users and R Markdown authors easily blend data, text, plots and htmlwidgets into beautiful HTML presentations that look great on the web, in print, and on screens.\nTogether we‚Äôll create a completely customized xaringan slide style with xaringanthemer, a package that lets you quickly create a complete slide theme from only a few color choices. Then we‚Äôll talk about how you can take your slide design one step further with just a little bit of CSS."
  },
  {
    "objectID": "talk/sliding-in-style-south-coast-ma/index.html#packages",
    "href": "talk/sliding-in-style-south-coast-ma/index.html#packages",
    "title": "Sliding in Style",
    "section": "Packages",
    "text": "Packages\n\nxaringan\nxaringanthemer\nxaringanExtra\nlorem\n\n# On CRAN\ninstall.packages(\"xaringan\")\ninstall.packages(\"xaringanthemer\", dependencies = TRUE)\n\n# From GitHub\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/xaringanExtra\")\nremotes::install_github(\"gadenbuie/lorem\")\nIf you use [docker], you can get set up with an [environment for this presentation][docker-image] with:\ndocker run -d --rm -p 8787:8787 -e DISABLE_AUTH=true grrrck/sliding-in-style"
  },
  {
    "objectID": "blog/educating-engineers-for-sustainability/index.html",
    "href": "blog/educating-engineers-for-sustainability/index.html",
    "title": "Educating Engineers for Sustainability",
    "section": "",
    "text": "I had the great pleasure of spending some time with Dr.¬†Richard Fenner, of the University of Cambridge, who is in the process of writing a new book on educating engineers for sustainability.\nThe talk was subtitled ‚ÄúPrinciples into Practice,‚Äù which is also the subtitle of his forthcoming book.\nI realized, through our talks and during his presentation, that while we have been very good as a culture at educating engineers in the application of scientific principles, we‚Äôve also created a breed of engineer that learns¬†how to solve a problem in a particular way‚Ä¶ at which point many new problems look like old problems and get solved in old, familiar ways.\nHe gave the example of the Army Corps of Engineers in the New Deal days, who were completely capable of damming rivers that had no business being dammed, only because they were good at building dams and had the money and skill to do so.\nI have friends who spend much of their lives lobbying for the removal of these dams. It turns out a dam that has no business being a dam is also highly detrimental to the local ecology.\nIt was great to hear his views on educating engineers in the new design criteria of sustainable development, and we had a few great conversations about what exactly sustainable actually means.\nHis program, like the masters program at the Patel School for Global Sustainability, trains students in critical sustainability practices, philosophies and ways of thinking. As an engineer ‚Äì or at least as a graduate of a highly engineering-focused school ‚Äì it was great to hear about new programs that build sustainability thinking on top of the foundation of engineering and ‚Äúhard science.‚Äù\nI look forward to reading Dr.¬†Fenner‚Äôs book when it is published ‚Äì I‚Äôll be sure to share it here."
  },
  {
    "objectID": "blog/lookup-citation-counts-with-r-and-rcrossref/index.html",
    "href": "blog/lookup-citation-counts-with-r-and-rcrossref/index.html",
    "title": "Lookup Citation Counts with R and rcrossref",
    "section": "",
    "text": "An R script and function that takes a citation key as a unique identifier for a paper and outputs the paper‚Äôs citation count.\nTo make it work you need to have your references stored in a BibTeX file with DOIs. The script looks up the citation key in the BibTeX file, and uses rcrossref to look up the citation count on CrossRef.\n\nAnd here‚Äôs the link to the script as a GitHub Gist."
  },
  {
    "objectID": "blog/lookup-citation-counts-with-r-and-rcrossref/index.html#footnotes",
    "href": "blog/lookup-citation-counts-with-r-and-rcrossref/index.html#footnotes",
    "title": "Lookup Citation Counts with R and rcrossref",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can download the code & files from the gist, or clone the gist from the command line by using: git clone https://gist.github.com/9b5609a6154753394f1a.git‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/new-website/index.html",
    "href": "blog/new-website/index.html",
    "title": "New Website",
    "section": "",
    "text": "Well hello there.\nI‚Äôm not exactly new to blogging. I‚Äôve started plenty of blogs in my life. Each new blog is an empty notebook, full of promise of a new project, a new stream of ideas, a new list of things to do, a new stream of creative surges and the vast empty space of 100 blank pages to hold them all.\nBut my notebooks are only half full. (Or is it half empty?) I never seem to make it all the way through before a new notebook comes along, or a new project or turn in my life creates a thematic change that requires breaking out of the old patterns of the old notebook.\nSo let‚Äôs hope this online notebook gets some notes. In the mean time, why not stalk me find out what I‚Äôm up to on twitter"
  },
  {
    "objectID": "blog/pupsters-at-the-window/index.html",
    "href": "blog/pupsters-at-the-window/index.html",
    "title": "The pupsters at the window",
    "section": "",
    "text": "The pupsters at the window."
  },
  {
    "objectID": "blog/remember-markdown-compile-commands-with-bash/index.html",
    "href": "blog/remember-markdown-compile-commands-with-bash/index.html",
    "title": "Remember markdown compile commands with bash",
    "section": "",
    "text": "I write everything in markdown and use pandoc nearly daily. It‚Äôs fast, easy, powerful and highly customizable. It handles math like a pro, and the recent addition of YAML headers makes it easier than ever to write and compile well-formatted documents that I can easily send to the web, print, or email to collaborators still stuck in Word.\nBecause pandoc separates form from content, reformatting citations, for example is as simple as changing the command from pandoc ... --csl=bad_style.csl to pandoc ... --csl=good_style.csl. Changing templates and fonts and bibliography files are just as easy.\nWhat‚Äôs hard is remembering exactly what series of commands I used to compile a document when I come back to it to make changes a week or even a few days later.\nMatt Might recently posted an excellent guide to using Bash, the Unix scripting and terminal language. Bash can be odd, but it‚Äôs certainly powerful. In fact, I use it frequently to outsource my memory and only really use the first 1% of what he teaches in his blog post."
  },
  {
    "objectID": "blog/remember-markdown-compile-commands-with-bash/index.html#it-gets-better",
    "href": "blog/remember-markdown-compile-commands-with-bash/index.html#it-gets-better",
    "title": "Remember markdown compile commands with bash",
    "section": "It gets better‚Ä¶",
    "text": "It gets better‚Ä¶\nAnother neat trick I picked up from this StackOverflow answer allows me to automate away all the typing out of extensions. With one additional line, the script below will strip the extension from the first argument, and add the second argument as the output extension. When combined with pandoc, this automatically sets the output type.\nTo compile 04-CHEM101-HW-BlahBlahBlah.markdown into PDF, simply run your compile script like this ./mycompile.sh 04-CHEM101-HW-BlahBlahBlah.markdown pdf. To compile again into Word format, just delete pdf and replace with docx.\nI am possibly too excited about this, but if you have any number of arguments in your pandoc script scrolling back through the lines of arguments is one more time suck you can avoid with a tiny bit of bash scripting. Love it.\n#!/bin/bash\n# input is ./script &lt;input file&gt; &lt;output extension&gt;\nname=`echo $1 | cut -f1 -d'.'`\npandoc $1 -o $name.$2 --bibliography=/path/to/library.bib --csl /path/to/citation_style.csl"
  },
  {
    "objectID": "blog/remember-markdown-compile-commands-with-bash/index.html#footnotes",
    "href": "blog/remember-markdown-compile-commands-with-bash/index.html#footnotes",
    "title": "Remember markdown compile commands with bash",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nUsually only when the working directory is not in my Dropbox folder. And also separately from any git repos.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/shiny-tip-option-where-to-run/index.html",
    "href": "blog/shiny-tip-option-where-to-run/index.html",
    "title": "Shiny Tip: Choose Where to Run App with an Option",
    "section": "",
    "text": "When you‚Äôre running a Shiny app from a source file, like app.R in RStudio, you can choose to run the app in the Viewer Pane, a new Window, or in an External browser window.\nThis works well for typical Shiny apps in app.R or {global,ui,server}.R, but if you‚Äôre building a Shiny app inside an R package ‚Äî and if you are, then definitely check out ThinkR‚Äôs golem package ‚Äî then that little Run App button won‚Äôt be available to choose where to run your Shiny apps.\nThe Shiny runApp() help documentation mentions the global option shiny.launch.browser but this helpful StackOverflow answer provided a helpful hint as to how to actually pick the Viewer, Window or External location for newly launched Shiny apps.\nThe following options only work in RStudio, and definitely in RStudio 1.2 (I‚Äôm running 1.2.1511). If you want to set these options globally in your ~/.Rprofile, then I‚Äôd recommend adding a conditional guard to check that RStudio is running first."
  },
  {
    "objectID": "blog/shiny-tip-option-where-to-run/index.html#rstudio-shiny.launch.browser-options",
    "href": "blog/shiny-tip-option-where-to-run/index.html#rstudio-shiny.launch.browser-options",
    "title": "Shiny Tip: Choose Where to Run App with an Option",
    "section": "RStudio shiny.launch.browser Options",
    "text": "RStudio shiny.launch.browser Options\n\nRun in Viewer\noptions(shiny.launch.browser = .rs.invokeShinyPaneViewer)\n\n\nRun in Window\noptions(shiny.launch.browser = .rs.invokeShinyWindowViewer)\n\n\nRun in External Browser\noptions(shiny.launch.browser = .rs.invokeShinyWindowExternal)"
  },
  {
    "objectID": "blog/the-book-of-us/index.html",
    "href": "blog/the-book-of-us/index.html",
    "title": "The Book of Us",
    "section": "",
    "text": "My little sister got married in November (and then turned 24 in December), so I wrote her a birthday/belated wedding song for her and her new husband."
  },
  {
    "objectID": "blog/the-book-of-us/index.html#the-book-of-us",
    "href": "blog/the-book-of-us/index.html#the-book-of-us",
    "title": "The Book of Us",
    "section": "The Book of Us",
    "text": "The Book of Us\nThe book began as an empty page\nI held the pen in my hand like a weather vane\nThen you walked in to my masquerade\nAnd that‚Äôs where we begin\nOur chapter opens in a cave\nWhen you stepped in to get out of the rain\nI gave you a made up name\nBut you played me at my game\nWhen I turn the page, we‚Äôre in a park\nReading words written from the heart\nIn the setting sun I‚Äôm a question mark\nQuivering in the dark\nWill you set me free when you‚Äôre lying next to me?\nWill time step aside when you say that you are mine?\nWill I read it in your eyes?\nSuddenly my life is a cosmic blur\nOf the city streets that we explore\nDiscovering what the word love is for\nWhen I hold you in my arms\nThen our chapter comes to its end\nWith sad goodbyes and I‚Äôll see you when\nI‚Äôll hold you in my heart till then\nAnd we‚Äôll write our book again\nChorus\nBut time knows better than we do, we do\nI never lost my state of mind when I‚Äôm with you\nI will always find my way to you, find me way back to you\nHere you‚Äôre standing next to me, I pledge my life to you\nI read your words and know that‚Ä¶\nChorus"
  },
  {
    "objectID": "blog/the-pandoc-markdown-rabbit-hole/index.html",
    "href": "blog/the-pandoc-markdown-rabbit-hole/index.html",
    "title": "The Pandoc Markdown rabbit hole",
    "section": "",
    "text": "I‚Äôve recently taken a hard dive into the deeply fragmented world of plaintext formatted markup languages. I currently have about 90 tabs open, each a winding, twisting trail leading through the world of Markdown, Multimarkdown, Pandoc, LaTeX, MathML, MathJax, and the other 500 slightly tweaked variants thereof.\nThis post is more of a way for me to plot the easiest path to get to where I am now ‚Äî a reference for the next time I have to do this. Maybe you‚Äôll find it useful. The world of markup languages, apps, helpers, commandline tools and viewers is littered with github pages, scripts left in github gists and fixes mentioned deep in the comments of support threads.\nSo, in hopes that this helps somebody else out, here are the apps and languages I have settled into. Today at least. We‚Äôll see how long it all lasts."
  },
  {
    "objectID": "blog/the-pandoc-markdown-rabbit-hole/index.html#why-markdown-why-not-just-use-word-or-latex",
    "href": "blog/the-pandoc-markdown-rabbit-hole/index.html#why-markdown-why-not-just-use-word-or-latex",
    "title": "The Pandoc Markdown rabbit hole",
    "section": "Why Markdown? Why not just use Word? Or LaTeX?",
    "text": "Why Markdown? Why not just use Word? Or LaTeX?\nBecause Word makes documents that look like shit. Because I put a lot of blood, tears and sweat into what I write and I‚Äôve seen too many hours lost to Word documents corrupted by one equation too many. Because Cambria Math makes equations that just look bad. Math is beautiful; I want a serious looking math font. Because you cannot change the default math font in Word (at least on Macs). Because writing should be easier.\nOn the flip side, when I write in LaTeX, I spend way too much time trying to figure out what commands will format text the way I want. Sure, the math is pretty and as long as I stick to the basic document classes things tend to look good. But the structure of Markdown is just so much easier that it gets out of the way of what I want to say. When you need the power of LaTeX, then it‚Äôs incredible. But mostly when I write in LaTeX I can‚Äôt help but constantly think of what could be."
  },
  {
    "objectID": "blog/the-pandoc-markdown-rabbit-hole/index.html#what-im-looking-for",
    "href": "blog/the-pandoc-markdown-rabbit-hole/index.html#what-im-looking-for",
    "title": "The Pandoc Markdown rabbit hole",
    "section": "What I‚Äôm looking for",
    "text": "What I‚Äôm looking for\nSo now that I know what I don‚Äôt want, here‚Äôs the short list of what I do want. Note that these intersect with the latest discussions about scholarly markdown.\n\nPlays well with math\nCan handle citations (or not mess them up too bad)\nTables are a plus\nFootnotes etc are cool, but not necessary\nPorts nicely to LaTeX, HTML, PDF and docx\n\nThat last one is huge. I once spent ~24 hours converting a paper written in Word to LaTeX because the equations were crashing Word and corrupting the file. Only to find out two weeks later that the funding agency only accepted .docx formats. Not funny."
  },
  {
    "objectID": "blog/the-pandoc-markdown-rabbit-hole/index.html#what-im-using-now",
    "href": "blog/the-pandoc-markdown-rabbit-hole/index.html#what-im-using-now",
    "title": "The Pandoc Markdown rabbit hole",
    "section": "What I‚Äôm using now",
    "text": "What I‚Äôm using now\nLet‚Äôs follow the writing flow.\n\nCreate the empty .mmd file somewhere where you want the file to be.\nText is written in plain text editor, preferably something that can highlight Markdown syntax. I‚Äôm using TextWrangler, but this choice is fluid.\nText is written in Pandoc extended markdown. Pandoc markdown lets you write LaTeX, and the benefits of being able to easily dump into .pdf, .docx, .tex, and .justaboutanything far outweigh the missing MultiMarkdown features.\nAs I write, I use the Marked.app to preview the document every time I hit ‚åò+s. But Marked doesn‚Äôt render Pandoc extended markdown. Luckily there‚Äôs a workaround that I‚Äôll talk about below.\nFinal versions can be turned into the right format using the pandoc command line. I haven‚Äôt learned the ins-and-outs of this yet, but the Pandoc demo page has cut-and-paste commands to do basically anything you can think of, at least in a basic version.\n\nThis is as far as I‚Äôve needed to go to date. There‚Äôs a lot more to learn, but this should be enough to get anybody started.\n\nWhat‚Äôs left to learn\n\nCitations\n\nI have a master .bib file for my citations so I can use any citekey from my library and know that they‚Äôll show up as long as I point pandoc to my bibtex file. That can be done using the following flag:--bibliography=/Users/.../Documents/PapersLibraryFull.bib\nDownload citation styles from zotero.org and save them somewhere safe. I‚Äôve created a folder in my home directory ~/.pandoc for storing these things, and I put my .csl files in ~/.pandoc/csl.To specify the citation style, use the --csl flag:--csl /Users/.../.pandoc/csl/ieee-with-url.csl\nIt‚Äôd be nice if the citation were inserted as a link to the full reference in the references section. This may be possible and I just haven‚Äôt figured it out yet.\n\nFormatting\n\nI know it‚Äôs possible to make very nice looking documents with pandoc templates. I just don‚Äôt know how to do this yet.\n\nEvernote\n\nI also need to figure out the best way to write text in this way and import into Evernote."
  },
  {
    "objectID": "blog/the-pandoc-markdown-rabbit-hole/index.html#pandoc-marked.app",
    "href": "blog/the-pandoc-markdown-rabbit-hole/index.html#pandoc-marked.app",
    "title": "The Pandoc Markdown rabbit hole",
    "section": "Pandoc + Marked.app",
    "text": "Pandoc + Marked.app\nBig thanks go to kjhealy for posting this shell script (and templates) to use Pandoc to render HTML in Marked.app.\nWhile I haven‚Äôt figured out how to use the pandoc templates he has developed, the shell script is phenomenal and works very well within Marked. I did make some changes to point pandoc to my Papers library bibtex file and to specify the citation style in advance.\n\nDownload and unzip the pandoc-templates package.\nOpen the preferences panel in Marked, and under the Styles tab add the .css files included in kjhealy‚Äôs package.\nThen, copy panmarked.sh somewhere central, like your home folder and open it in your favorite text editor.\nChange the bibliography flag to point at the right .bib file.\nAdd the --csl flag I mentioned above with the correct citation style.\nSave the edited file.\nIn the Behavior tab, enable Custom Markdown Processor and enter the full path to your edited panmarked.sh file.\nClick save.\nEnjoy beautifully rendered Pandoc markdown.\n\nYou can then edit panmarked.sh anytime to change the flags or arguments. You could also in theory copy the arguments into the Args box in the Marked app preference pane, but that box is small. Plus, it would have taken my way too long to figure that out from scratch, so big thanks again to kjhealy."
  },
  {
    "objectID": "blog/up-and-running/index.html",
    "href": "blog/up-and-running/index.html",
    "title": "Up and running‚Ä¶",
    "section": "",
    "text": "Update: No more Wordpress! It‚Äôs all Octopress up in here now.\nLooks like I‚Äôve got my new webpage up and running now. I‚Äôm really liking this theme. Okay, productive procrastination time is over now, time to get back to the real work."
  },
  {
    "objectID": "blog/use-google-forms-and-r-to-track-data-easily/index.html",
    "href": "blog/use-google-forms-and-r-to-track-data-easily/index.html",
    "title": "Use Google Forms and R to track data easily",
    "section": "",
    "text": "I‚Äôm going to show you a quick-and-dirty way to use Google Forms and a smartphone for in-the-field data collection. Of course, for me ‚Äúin-the-field data collection‚Äù really means keeping track of how much I weigh or how many cups of coffee I drank, but Google Forms is a powerful and versatile online form platform that can do a whole lot more.\nI‚Äôve tried other ‚Äúlife logging‚Äù apps, and while they‚Äôre useful at times, I‚Äôve found that all I really want is an easy to update spreadsheet. It turns out that a link to a Google Form on my iPhone is the perfect balance between ease and control.\nSo far, I‚Äôve used this method as a time card to track working hours, to track my daily weight, to stay on top of a group project, and to monitor the chemical balance and consumption of my pool. With Google Forms it‚Äôs easy to design a form that specifically fits your needs ‚Äì I‚Äôm sure there are a lot of other great ways this setup could be used."
  },
  {
    "objectID": "blog/use-google-forms-and-r-to-track-data-easily/index.html#create-the-form",
    "href": "blog/use-google-forms-and-r-to-track-data-easily/index.html#create-the-form",
    "title": "Use Google Forms and R to track data easily",
    "section": "Create the form",
    "text": "Create the form\nFire up Google Docs and create a new form from the ‚ÄúCreate‚Äù button. Give your form a name and pick a theme. The simpler themes tend to look better on mobile browsers; I tend to pick Dark Grey, but today I chose Magazine.\n\nGoogle will ask you if you want to save the responses in a separate spreadsheet, which seems like a good idea. Give the spreadsheet the name you want and move to the next step‚Ä¶ actually building the form.\nAdd the form items that you need, and try to find a balance between ease of collection and integrity of the data. I‚Äôve found that for numerical entries, the Plain Text format works best. If you want to allow multiple selections from a predetermined list, choose Checkboxes and then add your options. These will be stored in your spreadsheet as a single cell with a list of the selected options, ie: \"Option 1, Option 3\". You can also have a slider input on a scale of 1-5 or 0-10, but if precision is important ‚Äì eg. you might need to record 6.7 ‚Äì then skip this and use the plain text format.\n\nFor a the select only one option type item, the Choose from a list option works best, and shows up on the iPhone as a rolodex list. As an example, I‚Äôve added a question for the number of cups of coffee I‚Äôve had today.\n\nWhen you‚Äôre done with the questions, edit the form submitted confirmation response to something validating, like Good work, dude!, and decide if you want to allow edits. Then click Send Form and send the form to an email address that gets delivered to your phone."
  },
  {
    "objectID": "blog/use-google-forms-and-r-to-track-data-easily/index.html#get-smart-with-your-phone",
    "href": "blog/use-google-forms-and-r-to-track-data-easily/index.html#get-smart-with-your-phone",
    "title": "Use Google Forms and R to track data easily",
    "section": "Get smart with your phone",
    "text": "Get smart with your phone\nCheck your email on your phone and pull up the form you just created. It should look something like this.\n\nEnter your first data item. Here you can see the ‚Äúrolodex‚Äù selector is easy to use for a short list of about 5 or less options.\n\nIf you‚Äôre using Safari, then while you‚Äôre on the form page, tap the bookmark button and choose Add to Home Screen. Make sure you give the new link a short name so it displays nicely on the home screen. Now you‚Äôve got easy access to your form from your phone."
  },
  {
    "objectID": "blog/use-google-forms-and-r-to-track-data-easily/index.html#spreadsheets",
    "href": "blog/use-google-forms-and-r-to-track-data-easily/index.html#spreadsheets",
    "title": "Use Google Forms and R to track data easily",
    "section": "Spreadsheets",
    "text": "Spreadsheets\nNow that you‚Äôre set up with easy data collection from your phone, you‚Äôll want to do something with the data you‚Äôre collecting. All of the entries you submit are collected by Google into a spreadsheet you named at the beginning of the process.\n\nFrom here you can create graphs and charts, calculate summary statistics, etc. Everything a spreadsheet was meant to be. Of course, it‚Äôs best to do any calculations on a new sheet so that your work isn‚Äôt lost when new responses are recorded. One limitation I‚Äôve found is that columns are added to the spreadsheet as the items are added, so if you add a new item or rearrange questions in your form, the spreadsheet columns will be disorganized.\nOne of the greatest benefits of using Google Forms is that every entry is time stamped. Google‚Äôs timeline visualization is excellent, and once you have the data together it‚Äôs as easy as adding a chart."
  },
  {
    "objectID": "blog/xaringan-tip-logo-all-slides/index.html",
    "href": "blog/xaringan-tip-logo-all-slides/index.html",
    "title": "xaringan Tip: Add A Logo to All of Your Slides",
    "section": "",
    "text": "Here‚Äôs a quick tip to help solve a common xaringan problem: adding a logo to all of your slides.\nThe slightly problematic and somewhat annoying way to solve this problem is to add a logo to a series of slides using remarkjs‚Äô background-image and layout syntax.\nIt works‚Ä¶ as long as you don‚Äôt change your slide format or if you don‚Äôt mind repeating those 4 lines every time you need to reset your layout."
  },
  {
    "objectID": "blog/xaringan-tip-logo-all-slides/index.html#a-logo-for-all-the-slides",
    "href": "blog/xaringan-tip-logo-all-slides/index.html#a-logo-for-all-the-slides",
    "title": "xaringan Tip: Add A Logo to All of Your Slides",
    "section": "A logo for all the slides",
    "text": "A logo for all the slides\n\n\n\nThe xaringan logo appears on all the slides!\n\n\nüì∫ Demo Slides\nInstead, with a little bit of JavaScript and CSS, we can automatically insert a logo on all the slides in the presentation. Of course, we might not want a logo an all the slides, so we won‚Äôt add the logo to the .title-slide or any slide with class: hide-logo.\nIf you just want to jump straight to the solution, I‚Äôve created a template repository on GitHub that you can use to bootstrap your next set of xaringan slides.\nTo set everything up manually takes just a few steps.\n\nDownload your logo and save it in your slides directory. I‚Äôve used the xaringan hex logo: xaringan.png.\nDownload insert-logo.html into your slide directory, or copy the html described below into insert-logo.html.\nAdd insert-logo.html to your after_body includes in your slides‚Äô .Rmd file.\noutput:\nxaringan::moon_reader:\n  includes:\n    after_body: insert-logo.html\nEdit the .logo class in the CSS in insert-logo.html to use your logo image, and adjust the width, height and position (top, bottom, left, and/or right) as needed.\nUse class: hide-logo to hide your logo on individual slides. (The title slide is automatically excluded.)\n---\n\n# This slide has a logo\n\n---\nclass: inverse, hide-logo\n\n# This slide doesn't have a logo!\n\nAnd it's an inverse slide, too.\nHave fun looking üòé during your presentation!"
  },
  {
    "objectID": "blog/xaringan-tip-logo-all-slides/index.html#inside-insert-logo.html",
    "href": "blog/xaringan-tip-logo-all-slides/index.html#inside-insert-logo.html",
    "title": "xaringan Tip: Add A Logo to All of Your Slides",
    "section": "Inside insert-logo.html",
    "text": "Inside insert-logo.html\nThe insert-logo.html file is a simple snippet of CSS and a tiny bit of JavaScript. The CSS defines the .logo class that positions and sizes the logo, and the JavaScript inserts a &lt;div&gt; with class = \"logo\" into each slide.\n&lt;style&gt;\n.logo {\n  background-image: url(xaringan.png);\n  background-size: contain;\n  background-repeat: no-repeat;\n  position: absolute;\n  top: 1em;\n  right: 1em;\n  width: 110px;\n  height: 128px;\n  z-index: 0;\n}\n&lt;/style&gt;\n\n&lt;script&gt;\ndocument\n  .querySelectorAll(\n    '.remark-slide-content' +\n    ':not(.title-slide)' +\n    // add additional classes to exclude here, e.g.\n    // ':not(.inverse)' +\n    ':not(.hide-logo)'\n  )\n  .forEach(el =&gt; {\n    el.innerHTML += '&lt;div class=\"logo\"&gt;&lt;/div&gt;';\n  });\n&lt;/script&gt;\nIf you‚Äôd like to automatically keep the logo off certain slides, like the inverse slides, you can add additional :not(.class-to-exclude) to the CSS selector in the .querySelectorAll()."
  },
  {
    "objectID": "podcast/drake-intro-biodataclub/index.html",
    "href": "podcast/drake-intro-biodataclub/index.html",
    "title": "Reproducible Data Workflows With Drake",
    "section": "",
    "text": "drake is an R package that provides a powerful, flexible workflow management tool for reproducible data analysis pipelines. drake alleviates the pain of managing large (and even small) data analyses, speeding up iteration and development while providing reproducibility guarantees that are essential for modern research.\nhttps://ropensci.github.io/drake/\nIn this session, we‚Äôll learn how to use drake to manage a data analysis workflow by writing functions that define the steps of the analysis. We‚Äôll then learn how drake can keep track of all of these steps, from start to finish, and intelligently update only the outdated steps when your data or code change.\n\nMeeting prerequisites\nWe‚Äôll work through a few examples together, so please bring a laptop with the drake and visNetwork packages installed. (If you don‚Äôt have a laptop you can share with someone who does at the session.) You would also benefit from installing the tidyverse package for the session. See the full requirements here.\nrequired_packages &lt;- c(\n  # \"tidyverse\",  #&lt;&lt; For data processing, etc. (you probably have this)\n  \"here\",         #&lt;&lt; For sane path management\n  \"cowplot\",      #&lt;&lt; For composing ggplot2 plots\n  \"visNetwork\",   #&lt;&lt; For visualizing drake plans\n  \"drake\"         #&lt;&lt; Because drake\n)\n\ninstall.packages(required_packages)\nNote: if you‚Äôve used drake before, please ensure that you have version 7.0.0 or later installed.\n\n\nMeeting materials\nThe slides from this talk are available online at https://pkg.garrickadenbuie.com/drake-intro/ and the drake source code and RStudio project are in available on GitHub at https://github.com/gadenbuie/drake-intro. There is also an RStudio Cloud project containing the drake project with all of the required dependencies pre-installed that you can use to explore and run the code from the talk."
  },
  {
    "objectID": "podcast/informs-2013/index.html",
    "href": "podcast/informs-2013/index.html",
    "title": "Boosted Tree Ensembles for Predicting Postsurgical ICU Mortality",
    "section": "",
    "text": "Real-time monitoring of patient conditions in the ICU environment is essential in supporting clinical decisions and ensuring optimal allocation of medical resources. This study focuses on accurately predicting in-hospital ICU patient mortality utilizing functional profile data. We demonstrate that a boosted trees ensemble model is well suited for the diverse data typologies present in ICU data and provides an interpretable and accurate model to aid clinical experts in critical ICU decisions."
  },
  {
    "objectID": "podcast/isg-2018/index.html",
    "href": "podcast/isg-2018/index.html",
    "title": "Unsupervised behavior change detection using passive sensor systems in the homes of older adults",
    "section": "",
    "text": "Abstract\n\nPurpose\nGlobally and within the United States, we face well-known and documented challenges driven by growth within the elderly segments of our population. The majority of adults over 65 are healthy but managing one or more chronic illnesses, and older adults and their informal caregivers‚Äîsuch as family members and friends‚Äîrequire supportive technologies that assist in monitoring and managing these conditions1 as they strive to maintain independence at home. An important goal of lifestyle reassurance monitoring is to alert older adults and their caregivers to changes in behavior or routine. In contrast with traditional activity recognition algorithms that require labelled activity data that is both difficult and expensive to collect2, we present a method for unsupervised behavior change detection that does not require explicit, higher-level activity labels and is effective when applied to real-world, natural, smart home activity data.\n\n\nMethods\nIn this project, we developed a passive sensor system that has been installed to date in the homes of 14 community-dwelling, older adults (aged 68 and above) who live alone and were of good health at the time of installation. Participants responded to a bi-weekly survey tracking the occurrence of health changes. Included in the sensor network are motion sensors for the generalized detection of presence throughout the home, and magnetic contact sensors for detection of interaction with entrance and exit doors and routinely used objects. All sensors are wireless, use the Z-Wave protocol, and are readily available commercially. The basis of the behavior change algorithm is the use of a bag of event sequence n-grams representation3 to summarize daily activity patterns in an activity profile and a permutation-based change detection algorithm4 to compare activity profiles of multiple days (e.g.¬†a baseline period of activity) and individual or grouped activity profiles.\n\n\nResults and Discussion\nThe bag of event n-grams method was first validated as a supervised classification problem in which activity profiles were used to identify occupants from 6 homes with identical layouts. Activity profiles based on 4 and 6 weeks of activity led to correct identification of a given occupant for unlabelled days of activity with high accuracy (0.9593, 0.9624) and F1 (0.9590, 0.9621). The algorithm for unsupervised behavior change was applied to the activity data from four participants over a period of one year (one participant) or two years (three participants) who reported health changes ranging from acute episodes of illness to mobility restrictions leading to major surgery. Preliminary results reveal that comparison of activity profiles over time windows of 1 to 4 weeks reliably detects major shifts in behavior or other systematic disturbances such as guests in the home or sensor reliability issues. Linking the output of the algorithm to a notification system will alert family members, caregivers, and system administrators to trigger follow-up and review when such issues arise.\n\n\nReferences\n\nDemiris G, Hensel BK. Technologies for an aging society: A systematic review of ‚Äúsmart home‚Äù applications. Yearbook of medical informatics. 2008 Jan;33‚Äì40\nSzewcyzk S, Dwan K, Minor B, Swedlove B, Cook D. Annotating smart environment sensor data for activity learning. Technology and Health Care. 2009 Jan;17(3):161‚Äì169.\nHamid R, Johnson A, Batta S, Bobick A, Isbell C, Coleman G. Detection and explanation of anomalous activities: Representing activities as bags of event n-grams. Proceedings - 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2005. 2005;1031‚Äì1038.\nSprint G, Cook DJ, Schmitter-Edgecombe M. Unsupervised detection and analysis of changes in everyday physical activity data. Journal of Biomedical Informatics. 2016 Oct;63(Supplement C):54‚Äì65"
  },
  {
    "objectID": "talk/gentle-ggplot2-usf-asu/index.html",
    "href": "talk/gentle-ggplot2-usf-asu/index.html",
    "title": "A Gentle Guide to the Grammar of Graphics with ggplot2",
    "section": "",
    "text": "An intruction to data visualization with ggplot2 presented at the ‚ÄúWorkshop on Data Analysis Using R‚Äù hosted by the ASA student chapter at USF."
  },
  {
    "objectID": "talk/iie-iserc-2015/index.html",
    "href": "talk/iie-iserc-2015/index.html",
    "title": "Ambient Intelligence Applications in Healthcare",
    "section": "",
    "text": "In the past century, the world has experienced unprecedented growth in life expectancy concurrent with a growth in elderly population. Between 2010 and 2050, the number of people aged 65 and older is expected to more than double to exceed 88 million by 2050 in the United States. Ambient intelligence merges ubiquitous computing, embedded sensors, and artificial intelligence to monitor, adjust and respond to the environment of the user. This presentation will explore the potential of ambient intelligence for applications in health care, primarily with a focus on senior health care management."
  },
  {
    "objectID": "talk/informs-2017/index.html",
    "href": "talk/informs-2017/index.html",
    "title": "Occupant Activity Profiles from Smart Home Sensor Event Streams",
    "section": "",
    "text": "Faced with a growing elderly population, learning and characterizing activity profiles of smart home occupants will support senior health care management for older adults living in homes augmented by ambient intelligence solutions that combine ubiquitous computing and artificial intelligence. In this work, we explore a bag of n-grams approach for creating occupant-specific activity profiles from event streams collected from passive, embedded sensors in real-world sensor networks in the homes of several older adults."
  },
  {
    "objectID": "talk/js4shiny/index.html",
    "href": "talk/js4shiny/index.html",
    "title": "JavaScript for Shiny Users",
    "section": "",
    "text": "Shiny gives users a powerful toolkit to create interactive web applications. As a result, Shiny users are also web developers! Inevitably, an intermediate Shiny user will want to create a visualization or user interface that isn‚Äôt available in the shiny package. Fortunately, we can use the building blocks of the web ‚Äì JavaScript, HTML, and CSS ‚Äì to extend Shiny‚Äôs capabilities and create engaging Shiny apps.\nThis two-day, hands-on workshop will introduce Shiny users to JavaScript, the ubiquitous scripting language that powers the modern web. We will explore JavaScript‚Äôs syntax and will discover its functional programming style to be refreshingly familiar to tidyverse R users. We will learn how to use JavaScript to manipulate HTML and how Shiny uses JavaScript to communicate between the browser and Shiny server. Together, we will build an htmlwidget and learn how to incorporate our own or packaged JavaScript code into Shiny apps and [R Markdown] documents, and how to simultaneously manage JavaScript and R dependencies.\nThis workshop is for the Shiny user who boldly waded into the Customizing Shiny section of RStudio‚Äôs Shiny Articles and quickly wished they had more experience with JavaScript. This user recognizes the benefits of learning JavaScript, but they are overwhelmed by the sheer number of packages, tutorials, and StackOverflow questions that exist in the world about JavaScript, HTML, and CSS. The goal of this workshop is to meet the Shiny user where they are now to learn the best parts of JavaScript that will provide the most value and facilitate learning and exploration after the workshop."
  },
  {
    "objectID": "talk/js4shiny/index.html#abstract",
    "href": "talk/js4shiny/index.html#abstract",
    "title": "JavaScript for Shiny Users",
    "section": "",
    "text": "Shiny gives users a powerful toolkit to create interactive web applications. As a result, Shiny users are also web developers! Inevitably, an intermediate Shiny user will want to create a visualization or user interface that isn‚Äôt available in the shiny package. Fortunately, we can use the building blocks of the web ‚Äì JavaScript, HTML, and CSS ‚Äì to extend Shiny‚Äôs capabilities and create engaging Shiny apps.\nThis two-day, hands-on workshop will introduce Shiny users to JavaScript, the ubiquitous scripting language that powers the modern web. We will explore JavaScript‚Äôs syntax and will discover its functional programming style to be refreshingly familiar to tidyverse R users. We will learn how to use JavaScript to manipulate HTML and how Shiny uses JavaScript to communicate between the browser and Shiny server. Together, we will build an htmlwidget and learn how to incorporate our own or packaged JavaScript code into Shiny apps and [R Markdown] documents, and how to simultaneously manage JavaScript and R dependencies.\nThis workshop is for the Shiny user who boldly waded into the Customizing Shiny section of RStudio‚Äôs Shiny Articles and quickly wished they had more experience with JavaScript. This user recognizes the benefits of learning JavaScript, but they are overwhelmed by the sheer number of packages, tutorials, and StackOverflow questions that exist in the world about JavaScript, HTML, and CSS. The goal of this workshop is to meet the Shiny user where they are now to learn the best parts of JavaScript that will provide the most value and facilitate learning and exploration after the workshop."
  },
  {
    "objectID": "talk/presentable-user2021/index.html",
    "href": "talk/presentable-user2021/index.html",
    "title": "Professional, Polished, Presentable",
    "section": "",
    "text": "The xaringan package brings professional, impressive, and visually appealing slides to the powerful R Markdown ecosystem. Through our hands-on tutorial, you will learn how to design highly effective slides that support presentations for teaching and reporting alike. Over three hours, you will learn how to create an accessible baseline design that matches your institution or organization‚Äôs style guide. Together we‚Äôll explore the basics of CSS‚Äîthe design language of the internet‚Äîand how we can leverage CSS to produce elegant slides for effective communication."
  },
  {
    "objectID": "talk/presentable-user2021/index.html#abstract",
    "href": "talk/presentable-user2021/index.html#abstract",
    "title": "Professional, Polished, Presentable",
    "section": "",
    "text": "The xaringan package brings professional, impressive, and visually appealing slides to the powerful R Markdown ecosystem. Through our hands-on tutorial, you will learn how to design highly effective slides that support presentations for teaching and reporting alike. Over three hours, you will learn how to create an accessible baseline design that matches your institution or organization‚Äôs style guide. Together we‚Äôll explore the basics of CSS‚Äîthe design language of the internet‚Äîand how we can leverage CSS to produce elegant slides for effective communication."
  },
  {
    "objectID": "talk/presentable-user2021/index.html#why-xaringan",
    "href": "talk/presentable-user2021/index.html#why-xaringan",
    "title": "Professional, Polished, Presentable",
    "section": "Why xaringan?",
    "text": "Why xaringan?\nEffective communication is the keystone of impactful data science. Whether teaching data-related skills or reporting the latest modelling results, by and large R users are expected to communicate highly complex topics to students and stakeholders. Furthermore, our computational data work requires that our presentations and reports are both reproducible when we need to recreate today‚Äôs work in the future, as well as adaptable when tomorrow‚Äôs data changes today‚Äôs results. And, not least of all, effective communication demands that our medium of communication is accessible to all, regardless of socio-economic status, activity limitations or disability.\nCreating presentations with the xaringan package embodies all of these requisite skills: built on the literate programming markdown syntax familiar to users of R Markdown, it produces reproducible HTML slides that enable effective, accessible communication across sectors, disciplines, and experiences.\nAlong the way, working with xaringan fosters a level of web literacy that is immensely useful in many other venues of online communication such as with web-based documents and apps created using R Markdown and Shiny."
  },
  {
    "objectID": "talk/trug-extra-awesome-xaringan/index.html",
    "href": "talk/trug-extra-awesome-xaringan/index.html",
    "title": "Extra Awesome xaringan Presentations",
    "section": "",
    "text": "Learn how to make extra awesome xaringan presentations with a few new packages\n\nxaringanthemer\nxaringanExtra\nmetathis\n\nthat add the extra touches needed to personalize your slides and make them stand out from the crowd."
  },
  {
    "objectID": "talk/trug-extra-awesome-xaringan/index.html#description",
    "href": "talk/trug-extra-awesome-xaringan/index.html#description",
    "title": "Extra Awesome xaringan Presentations",
    "section": "",
    "text": "Learn how to make extra awesome xaringan presentations with a few new packages\n\nxaringanthemer\nxaringanExtra\nmetathis\n\nthat add the extra touches needed to personalize your slides and make them stand out from the crowd."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "My Blog",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nHow to enable your Quarto blogs to accept comments with Giscus\n\n\n\nwebsite building\n\n\n\nTBD\n\n\n\n\n\nMay 16, 2025\n\n1 min\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "podcast/index.html",
    "href": "podcast/index.html",
    "title": "Talks and Presentations",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAchieving Concurrency in Streamlit with a RQ scheduler, Building Responsive Data Applications\n\n\n\nConference\n\n\n\nTBD\n\n\n\n\n\nJun 1, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Yue Harriet Huang",
    "section": "",
    "text": "GitHub\n  \n  \n    \n     YouTube\n  \n\n  \n  \n\nüëã Hey there!\n\n\nI‚Äôm Yue Harriet Huang. I‚Äôm a Data Technologist that is enthusiastic about civic tech for public good and advocating for democratization of the latest data technologies. I build tools using Python, Azure cloud technologies to help you deliver analytics solution."
  },
  {
    "objectID": "about/index.html#about-me",
    "href": "about/index.html#about-me",
    "title": "Yue Harriet Huang",
    "section": "About Me",
    "text": "About Me\nI‚Äôm a passionate Python user and educator. I build [analytical tools] and data dashboards using FastAPI, Streamlit, Taipy.\n\nLet‚Äôs do something awesome together!\nIf you‚Äôre interested in working with me, please drop me a line at dariahuangster@gmail.com!\n\n\nA little bit more about me‚Ä¶"
  },
  {
    "objectID": "podcast/bslib-modern-dashboards/index.html",
    "href": "podcast/bslib-modern-dashboards/index.html",
    "title": "Achieving Concurrency in Streamlit with a RQ scheduler, Building Responsive Data Applications",
    "section": "",
    "text": "With increasing adoption of Streamlit to create interactive data applications in the usage of generative AI technologies, a challenge of maintaining responsiveness under heavy or concurrent user interactions has emerged as applications grow in complexity, sometimes with a long-running background job. This is where integrating task queueing systems like Redis Queue (RQ) into Streamlit applications can come in handy.\nIn this talk, we will explore how we can enable this integration between RQ and Streamlit to achieve concurrency, improve user experiences and effectively manage long-running tasks."
  },
  {
    "objectID": "podcast/bslib-modern-dashboards/index.html#abstract",
    "href": "podcast/bslib-modern-dashboards/index.html#abstract",
    "title": "Achieving Concurrency in Streamlit with a RQ scheduler, Building Responsive Data Applications",
    "section": "",
    "text": "With increasing adoption of Streamlit to create interactive data applications in the usage of generative AI technologies, a challenge of maintaining responsiveness under heavy or concurrent user interactions has emerged as applications grow in complexity, sometimes with a long-running background job. This is where integrating task queueing systems like Redis Queue (RQ) into Streamlit applications can come in handy.\nIn this talk, we will explore how we can enable this integration between RQ and Streamlit to achieve concurrency, improve user experiences and effectively manage long-running tasks."
  },
  {
    "objectID": "colophon/index.html#inspired-by-garrick-aden-buie-made-with-quarto",
    "href": "colophon/index.html#inspired-by-garrick-aden-buie-made-with-quarto",
    "title": "Made with üíô",
    "section": "",
    "text": "Made with  Quarto, which is powered by pandoc.\nThe previous version of this blog was made with  Hugo Ap√©ro , which is based on  Blogophonic  by Formspree and was powered by blogdown and built by Hugo.\nThe original source for this blog can be found online at GitHub gadenbuie/garrickadenbuie-com."
  },
  {
    "objectID": "project/cleanrmd/index.html",
    "href": "project/cleanrmd/index.html",
    "title": "üßº TBD",
    "section": "",
    "text": "Follow @harriet¬† Star"
  },
  {
    "objectID": "project/epoxy/index.html",
    "href": "project/epoxy/index.html",
    "title": "{epoxy}",
    "section": "",
    "text": "Follow @gadenbuie\n{epoxy}\n\n\nextra-strength glue for scripts, reports, and apps.\n\n\n\n     \n\n\nepoxy is super glue\n\nIn R Markdown and Quarto reports\nUse epoxy chunks for extra-strength inline syntax. Just library(epoxy) in your R Markdown or Quarto document to get started. All epoxy chunks make it easy to transform values in place with a {cli}-inspired inline syntax described in ?epoxy_transform_inline.\n\n\nIn R scripts\nThe same functions that power epoxy chunks are availble in three flavors:\n\nepoxy() for markdown and general purpose outputs\nepoxy_html() for HTML outputs, with added support for HTML templating (see ?epoxy_transform_html)\nepoxy_latex() for LaTeX reports\n\nThese functions are accompanied by a robust system for chained glue-transformers powered by epoxy_transform().\n\n\nIn Shiny apps\nui_epoxy_html() makes it easy to update text or HTML dynamically, anywhere in your Shiny app‚Äôs UI. For more complicated situations, ui_epoxy_mustache() lets you turn any Shiny UI into a template that leverages the Mustache templating language.\n\n\n\nepoxy in R Markdown and Quarto documents\nIn R Markdown and Quarto documents, epoxy gives you an epoxy chunk where you can write in markdown, blending prose and data using glue‚Äôs template syntax.\nHere‚Äôs an example using a small list containing data about a movie (expand the section below to see the full code for movie). We can use the inline transformer to format the replacement text as we build up a description from this data.\n\n\nMovie data\n\nmovie &lt;- list(\n  year = 1989,\n  title = \"Back to the Future Part II\",\n  budget = 4e+07,\n  domgross = 118450002,\n  imdb_rating = 7.8,\n  actors = c(\n    \"Michael J. Fox\",\n    \"Christopher Lloyd\",\n    \"Lea Thompson\",\n    \"Thomas F. Wilson\"\n  ),\n  runtime = 108L\n)\n\n```{epoxy}\nThe movie {.emph {.titlecase movie$title}}\nwas released in {.strong movie$year}.\nIt earned {.dollar movie$domgross}\nwith a budget of {.dollar movie$budget},\nand it features movie stars\n{.and movie$actors}.\n```\n\nThe movie Back to the Future Part II was released in 1989. It earned $118,450,002 with a budget of $40,000,000, and it features movie stars Michael J. Fox, Christopher Lloyd, Lea Thompson, and Thomas F. Wilson.\n\nLearn more about epoxy chunks ‚Äì and its siblings epoxy_html and epoxy_latex ‚Äì in Getting Started. Or read more about epoxy‚Äôs inline formatting in ?epoxy_transform_inline.\n\n\nInstallation\nYou can install epoxy from CRAN:\ninstall.packages(\"epoxy\")\nYou can install the latest development version of epoxy with remotes\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/epoxy\")\nor from gadenbuie.r-universe.dev.\noptions(repos = c(\n  gadenbuie = \"https://gadenbuie.r-universe.dev/\",\n  getOption(\"repos\")\n))\n\ninstall.packages(\"epoxy\")\n\n\nSetup\nlibrary(epoxy)\nLoading epoxy adds four new knitr engines, or chunk types. Each type lets you intermix text with R code or data (expr in the table below), and each is geared toward a different output context.\n\n\n\nEngine\nOutput Context\nDelimiter\n\n\n\n\nepoxy\nall-purpose markdown\n{expr}\n\n\nepoxy_html\nHTML\n{expr}\n\n\nepoxy_latex\nLaTeX\n&lt;&lt;expr&gt;&gt;\n\n\nwhisker\nall-purpose\nmustache template language\n\n\n\n‚ö†Ô∏è Caution: Previously, epoxy provided a glue engine, but this conflicts with a similar chunk engine by the glue package. You can update existing documents to use the epoxy engine, or you can explicitly use epoxy‚Äôs glue chunk by including the following in your setup chunk.\nuse_epoxy_glue_engine()\n\n\nUse epoxy\nTo use epoxy in your R Markdown document, create a new chunk using the engine of your choice. In that chunk, write in markdown, HTML, or LaTeX as needed, wrapping R expressions inside the delimiters for the epoxy chunk.\n```{epoxy}\nThe average speed of the cars was **{mean(cars$speed)} mph.**\nBut on average the distance traveled was only _{mean(cars$dist)}_.\n```\nThe average speed of the cars was 15.4 mph. But on average the distance traveled was only 42.98 ft.\nepoxy is built around glue::glue(), which evaluates the R expressions in the { } and inserts the results into the string. The chunk above is equivalent to this call to glue::glue():\nglue::glue(\"The average speed of the cars was **{mean(cars$speed)} mph**.\nBut on average the distance traveled was only _{mean(cars$dist)} ft_.\")\n#&gt; The average speed of the cars was **15.4 mph**.\n#&gt; But on average the distance traveled was only _42.98 ft_.\nOne immediate advantage of using epoxy instead of glue::glue() is that RStudio‚Äôs autocompletion feature works inside epoxy chunks! Typing cars$ in the chunk will suggest the columns of cars.\n\n\nLearn more\nThere‚Äôs a whole lot more that epoxy can do! Learn more:\n\nepoxy Package Documentation\nGetting Started\nInline Reporting with epoxy\n\n\n\nCode of Conduct\nPlease note that the epoxy project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms."
  },
  {
    "objectID": "project/epoxy/index.html#epoxy-is-super-glue",
    "href": "project/epoxy/index.html#epoxy-is-super-glue",
    "title": "{epoxy}",
    "section": "epoxy is super glue",
    "text": "epoxy is super glue\n\nIn R Markdown and Quarto reports\nUse epoxy chunks for extra-strength inline syntax. Just library(epoxy) in your R Markdown or Quarto document to get started. All epoxy chunks make it easy to transform values in place with a {cli}-inspired inline syntax described in ?epoxy_transform_inline.\n\n\nIn R scripts\nThe same functions that power epoxy chunks are availble in three flavors:\n\nepoxy() for markdown and general purpose outputs\nepoxy_html() for HTML outputs, with added support for HTML templating (see ?epoxy_transform_html)\nepoxy_latex() for LaTeX reports\n\nThese functions are accompanied by a robust system for chained glue-transformers powered by epoxy_transform().\n\n\nIn Shiny apps\nui_epoxy_html() makes it easy to update text or HTML dynamically, anywhere in your Shiny app‚Äôs UI. For more complicated situations, ui_epoxy_mustache() lets you turn any Shiny UI into a template that leverages the Mustache templating language."
  },
  {
    "objectID": "project/epoxy/index.html#epoxy-in-r-markdown-and-quarto-documents",
    "href": "project/epoxy/index.html#epoxy-in-r-markdown-and-quarto-documents",
    "title": "{epoxy}",
    "section": "epoxy in R Markdown and Quarto documents",
    "text": "epoxy in R Markdown and Quarto documents\nIn R Markdown and Quarto documents, epoxy gives you an epoxy chunk where you can write in markdown, blending prose and data using glue‚Äôs template syntax.\nHere‚Äôs an example using a small list containing data about a movie (expand the section below to see the full code for movie). We can use the inline transformer to format the replacement text as we build up a description from this data.\n\n\nMovie data\n\nmovie &lt;- list(\n  year = 1989,\n  title = \"Back to the Future Part II\",\n  budget = 4e+07,\n  domgross = 118450002,\n  imdb_rating = 7.8,\n  actors = c(\n    \"Michael J. Fox\",\n    \"Christopher Lloyd\",\n    \"Lea Thompson\",\n    \"Thomas F. Wilson\"\n  ),\n  runtime = 108L\n)\n\n```{epoxy}\nThe movie {.emph {.titlecase movie$title}}\nwas released in {.strong movie$year}.\nIt earned {.dollar movie$domgross}\nwith a budget of {.dollar movie$budget},\nand it features movie stars\n{.and movie$actors}.\n```\n\nThe movie Back to the Future Part II was released in 1989. It earned $118,450,002 with a budget of $40,000,000, and it features movie stars Michael J. Fox, Christopher Lloyd, Lea Thompson, and Thomas F. Wilson.\n\nLearn more about epoxy chunks ‚Äì and its siblings epoxy_html and epoxy_latex ‚Äì in Getting Started. Or read more about epoxy‚Äôs inline formatting in ?epoxy_transform_inline."
  },
  {
    "objectID": "project/epoxy/index.html#installation",
    "href": "project/epoxy/index.html#installation",
    "title": "{epoxy}",
    "section": "Installation",
    "text": "Installation\nYou can install epoxy from CRAN:\ninstall.packages(\"epoxy\")\nYou can install the latest development version of epoxy with remotes\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/epoxy\")\nor from gadenbuie.r-universe.dev.\noptions(repos = c(\n  gadenbuie = \"https://gadenbuie.r-universe.dev/\",\n  getOption(\"repos\")\n))\n\ninstall.packages(\"epoxy\")"
  },
  {
    "objectID": "project/epoxy/index.html#setup",
    "href": "project/epoxy/index.html#setup",
    "title": "{epoxy}",
    "section": "Setup",
    "text": "Setup\nlibrary(epoxy)\nLoading epoxy adds four new knitr engines, or chunk types. Each type lets you intermix text with R code or data (expr in the table below), and each is geared toward a different output context.\n\n\n\nEngine\nOutput Context\nDelimiter\n\n\n\n\nepoxy\nall-purpose markdown\n{expr}\n\n\nepoxy_html\nHTML\n{expr}\n\n\nepoxy_latex\nLaTeX\n&lt;&lt;expr&gt;&gt;\n\n\nwhisker\nall-purpose\nmustache template language\n\n\n\n‚ö†Ô∏è Caution: Previously, epoxy provided a glue engine, but this conflicts with a similar chunk engine by the glue package. You can update existing documents to use the epoxy engine, or you can explicitly use epoxy‚Äôs glue chunk by including the following in your setup chunk.\nuse_epoxy_glue_engine()"
  },
  {
    "objectID": "project/epoxy/index.html#use-epoxy",
    "href": "project/epoxy/index.html#use-epoxy",
    "title": "{epoxy}",
    "section": "Use epoxy",
    "text": "Use epoxy\nTo use epoxy in your R Markdown document, create a new chunk using the engine of your choice. In that chunk, write in markdown, HTML, or LaTeX as needed, wrapping R expressions inside the delimiters for the epoxy chunk.\n```{epoxy}\nThe average speed of the cars was **{mean(cars$speed)} mph.**\nBut on average the distance traveled was only _{mean(cars$dist)}_.\n```\nThe average speed of the cars was 15.4 mph. But on average the distance traveled was only 42.98 ft.\nepoxy is built around glue::glue(), which evaluates the R expressions in the { } and inserts the results into the string. The chunk above is equivalent to this call to glue::glue():\nglue::glue(\"The average speed of the cars was **{mean(cars$speed)} mph**.\nBut on average the distance traveled was only _{mean(cars$dist)} ft_.\")\n#&gt; The average speed of the cars was **15.4 mph**.\n#&gt; But on average the distance traveled was only _42.98 ft_.\nOne immediate advantage of using epoxy instead of glue::glue() is that RStudio‚Äôs autocompletion feature works inside epoxy chunks! Typing cars$ in the chunk will suggest the columns of cars."
  },
  {
    "objectID": "project/epoxy/index.html#learn-more",
    "href": "project/epoxy/index.html#learn-more",
    "title": "{epoxy}",
    "section": "Learn more",
    "text": "Learn more\nThere‚Äôs a whole lot more that epoxy can do! Learn more:\n\nepoxy Package Documentation\nGetting Started\nInline Reporting with epoxy"
  },
  {
    "objectID": "project/epoxy/index.html#code-of-conduct",
    "href": "project/epoxy/index.html#code-of-conduct",
    "title": "{epoxy}",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nPlease note that the epoxy project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms."
  },
  {
    "objectID": "talk/bslib-modern-dashboards/index.html",
    "href": "talk/bslib-modern-dashboards/index.html",
    "title": "Achieving Concurrency in Streamlit with a RQ scheduler, Building Responsive Data Applications",
    "section": "",
    "text": "With increasing adoption of Streamlit to create interactive data applications in the usage of generative AI technologies, a challenge of maintaining responsiveness under heavy or concurrent user interactions has emerged as applications grow in complexity, sometimes with a long-running background job. This is where integrating task queueing systems like Redis Queue (RQ) into Streamlit applications can come in handy.\nIn this talk, we will explore how we can enable this integration between RQ and Streamlit to achieve concurrency, improve user experiences and effectively manage long-running tasks."
  },
  {
    "objectID": "blog/llm-work-summary/index.html",
    "href": "blog/llm-work-summary/index.html",
    "title": "How to enable your Quarto blogs to accept comments with Giscus",
    "section": "",
    "text": "storage database: GitHub repository\ninstall Giscus app to your GitHub repository\nenable discussion feature in your repo"
  },
  {
    "objectID": "blog/llm-work-summary/index.html#references",
    "href": "blog/llm-work-summary/index.html#references",
    "title": "How to enable your Quarto blogs to accept comments with Giscus",
    "section": "References",
    "text": "References\nAdding Comments"
  },
  {
    "objectID": "blog/llm-work-summary/index.html#how-does-it-work",
    "href": "blog/llm-work-summary/index.html#how-does-it-work",
    "title": "How to enable your Quarto blogs to accept comments with Giscus",
    "section": "",
    "text": "storage database: GitHub repository\ninstall Giscus app to your GitHub repository\nenable discussion feature in your repo"
  }
]